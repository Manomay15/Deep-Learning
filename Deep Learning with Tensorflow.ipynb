{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5d4a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d67a572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2c78137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d209dd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0c7f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f447c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_full, y_train_full), (x_test, y_test) = fashion.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6175531b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_full.shape, x_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2b1b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, x_train = x_train_full[:5000] / 255.0, x_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74539529",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "\"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64687ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 7, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "350448fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2254c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5d66879",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "model.add(keras.layers.Dense(300, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9e276a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "632ae65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "929d1739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.flatten.Flatten at 0x27a1454db20>,\n",
       " <keras.layers.core.dense.Dense at 0x27a1454dbe0>,\n",
       " <keras.layers.core.dense.Dense at 0x27a0d164d90>,\n",
       " <keras.layers.core.dense.Dense at 0x27a0cf0e370>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddfdfdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88de0dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "817e9545",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee11dadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06751125,  0.00775318, -0.02924701, ...,  0.04567416,\n",
       "         0.03267841,  0.0380911 ],\n",
       "       [ 0.03457145, -0.03649315, -0.02032341, ...,  0.01309534,\n",
       "        -0.01842552, -0.00871204],\n",
       "       [-0.0468975 ,  0.03386655,  0.0312499 , ..., -0.00492282,\n",
       "        -0.0424252 ,  0.01352705],\n",
       "       ...,\n",
       "       [-0.07336517,  0.07078707, -0.05570103, ..., -0.02187962,\n",
       "         0.07143778,  0.00628284],\n",
       "       [ 0.05305302, -0.04337604, -0.05876186, ...,  0.07092023,\n",
       "        -0.02913256,  0.03021232],\n",
       "       [ 0.03397132,  0.05362034, -0.03415754, ...,  0.00965808,\n",
       "         0.03216071, -0.0649694 ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "406da288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5b2d3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e7e2c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2900bad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7105 - accuracy: 0.7681 - val_loss: 0.5297 - val_accuracy: 0.8112\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4841 - accuracy: 0.8315 - val_loss: 0.4393 - val_accuracy: 0.8520\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4419 - accuracy: 0.8452 - val_loss: 0.4082 - val_accuracy: 0.8586\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4149 - accuracy: 0.8543 - val_loss: 0.4061 - val_accuracy: 0.8614\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3955 - accuracy: 0.8611 - val_loss: 0.3869 - val_accuracy: 0.8610\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3807 - accuracy: 0.8663 - val_loss: 0.3878 - val_accuracy: 0.8670\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3673 - accuracy: 0.8703 - val_loss: 0.3663 - val_accuracy: 0.8744\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3557 - accuracy: 0.8732 - val_loss: 0.3502 - val_accuracy: 0.8800\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3448 - accuracy: 0.8775 - val_loss: 0.3813 - val_accuracy: 0.8666\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3359 - accuracy: 0.8799 - val_loss: 0.3489 - val_accuracy: 0.8790\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3281 - accuracy: 0.8823 - val_loss: 0.3471 - val_accuracy: 0.8776\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3187 - accuracy: 0.8853 - val_loss: 0.3401 - val_accuracy: 0.8792\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3116 - accuracy: 0.8870 - val_loss: 0.3259 - val_accuracy: 0.8826\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3041 - accuracy: 0.8899 - val_loss: 0.3404 - val_accuracy: 0.8770\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2969 - accuracy: 0.8937 - val_loss: 0.3286 - val_accuracy: 0.8862\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2915 - accuracy: 0.8944 - val_loss: 0.3118 - val_accuracy: 0.8852\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2848 - accuracy: 0.8978 - val_loss: 0.3088 - val_accuracy: 0.8886\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2801 - accuracy: 0.8993 - val_loss: 0.3060 - val_accuracy: 0.8882\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2742 - accuracy: 0.9009 - val_loss: 0.3255 - val_accuracy: 0.8852\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2693 - accuracy: 0.9037 - val_loss: 0.3104 - val_accuracy: 0.8858\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2636 - accuracy: 0.9043 - val_loss: 0.3127 - val_accuracy: 0.8910\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2598 - accuracy: 0.9060 - val_loss: 0.3039 - val_accuracy: 0.8904\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2548 - accuracy: 0.9085 - val_loss: 0.3133 - val_accuracy: 0.8850\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2500 - accuracy: 0.9096 - val_loss: 0.3103 - val_accuracy: 0.8858\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2461 - accuracy: 0.9111 - val_loss: 0.3103 - val_accuracy: 0.8872\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2422 - accuracy: 0.9131 - val_loss: 0.3103 - val_accuracy: 0.8922\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2369 - accuracy: 0.9150 - val_loss: 0.3069 - val_accuracy: 0.8856\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2335 - accuracy: 0.9171 - val_loss: 0.3152 - val_accuracy: 0.8860\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2305 - accuracy: 0.9169 - val_loss: 0.2988 - val_accuracy: 0.8954\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2250 - accuracy: 0.9196 - val_loss: 0.2933 - val_accuracy: 0.8946\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=30,validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07666bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot()\n",
    "# plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3dc0c951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 58.7773 - accuracy: 0.8595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[58.77726745605469, 0.859499990940094]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8f2da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = x_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9332486",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = model.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89e94908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "236da1a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-95de46adb07b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46f95867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred=model.predict(x_new)\n",
    "classes_x=np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b195c99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d25d8e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f837a57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[classes_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92de25ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d227c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "320a8dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f80b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_full, x_test, y_train_full, y_test = train_test_split(housing.data, housing.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1efa7b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6369b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f1b338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = scaler.fit_transform(x_train)\n",
    "x_valid = scaler.transform(x_valid)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "202b29ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=x_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "487783ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54010d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9263 - val_loss: 0.5904\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0728 - val_loss: 0.5147\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5328 - val_loss: 0.4577\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4360 - val_loss: 0.4273\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4310 - val_loss: 0.4251\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4098 - val_loss: 0.4402\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4325 - val_loss: 0.4063\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3978 - val_loss: 0.3998\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3910 - val_loss: 0.3975\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3870 - val_loss: 0.3945\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3973 - val_loss: 0.4085\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3808 - val_loss: 0.3882\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3779 - val_loss: 0.3901\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3691 - val_loss: 0.3758\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3671 - val_loss: 0.3793\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3655 - val_loss: 0.3712\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3651 - val_loss: 0.3804\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3621 - val_loss: 0.3680\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3639 - val_loss: 0.3740\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3594 - val_loss: 0.3661\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=20,\n",
    "    validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d103b1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.3570\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc4d039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = x_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "239ca94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3995e3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3280334],\n",
       "       [1.450681 ],\n",
       "       [1.0356427]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "557e9cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a6ab0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "298b575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80538f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = keras.layers.Concatenate()([input_, hidden2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c48bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = keras.layers.Dense(1)(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9160de96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b07ecc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ed198e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0514 - val_loss: 0.5800\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0537 - val_loss: 0.5250\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7061 - val_loss: 0.4881\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4751 - val_loss: 0.4945\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5996 - val_loss: 0.4524\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4397 - val_loss: 0.5111\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4227 - val_loss: 0.4144\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4346 - val_loss: 0.4170\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4925 - val_loss: 0.4008\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3930 - val_loss: 0.3943\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4779 - val_loss: 0.3919\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3975 - val_loss: 0.3816\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3753 - val_loss: 0.3722\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3726 - val_loss: 0.3741\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3596 - val_loss: 0.3665\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4321 - val_loss: 0.3588\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3728 - val_loss: 0.3579\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3497 - val_loss: 0.3651\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5507 - val_loss: 0.3463\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3459 - val_loss: 0.3461\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=20,\n",
    "    validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b79e18c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3606\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5fece1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bdddf371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 2.0977 - val_loss: 0.8381\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7556 - val_loss: 0.6978\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6130 - val_loss: 0.5990\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5673 - val_loss: 0.5709\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5483 - val_loss: 0.5534\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5352 - val_loss: 0.5427\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5291 - val_loss: 0.5319\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5197 - val_loss: 0.5254\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5121 - val_loss: 0.5184\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5069 - val_loss: 0.5160\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5046 - val_loss: 0.5119\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5020 - val_loss: 0.5067\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4989 - val_loss: 0.5035\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4952 - val_loss: 0.5021\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4932 - val_loss: 0.4975\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4893 - val_loss: 0.4967\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4879 - val_loss: 0.4923\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4849 - val_loss: 0.4920\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4838 - val_loss: 0.4884\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4815 - val_loss: 0.4879\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4860\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "x_train_A, x_train_B = x_train[:, :5], x_train[:, 2:]\n",
    "x_valid_A, x_valid_B = x_valid[:, :5], x_valid[:, 2:]\n",
    "x_test_A, x_test_B = x_test[:, :5], x_test[:, 2:]\n",
    "x_new_A, x_new_B = x_test_A[:3], x_test_B[:3]\n",
    "history = model.fit((x_train_A, x_train_B), y_train, epochs=20,\n",
    " validation_data=((x_valid_A, x_valid_B), y_valid))\n",
    "mse_test = model.evaluate((x_test_A, x_test_B), y_test)\n",
    "y_pred = model.predict((x_new_A, x_new_B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "30076638",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "36112bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3d207165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 0.8315 - main_output_loss: 0.7597 - aux_output_loss: 1.4770 - val_loss: 0.5648 - val_main_output_loss: 0.5047 - val_aux_output_loss: 1.1062\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5678 - main_output_loss: 0.5168 - aux_output_loss: 1.0272 - val_loss: 0.5347 - val_main_output_loss: 0.4889 - val_aux_output_loss: 0.9468\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5454 - main_output_loss: 0.5067 - aux_output_loss: 0.8939 - val_loss: 0.5562 - val_main_output_loss: 0.5251 - val_aux_output_loss: 0.8359\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5335 - main_output_loss: 0.5039 - aux_output_loss: 0.8003 - val_loss: 0.4912 - val_main_output_loss: 0.4620 - val_aux_output_loss: 0.7541\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4862 - main_output_loss: 0.4581 - aux_output_loss: 0.7395 - val_loss: 0.4775 - val_main_output_loss: 0.4523 - val_aux_output_loss: 0.7045\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4756 - main_output_loss: 0.4506 - aux_output_loss: 0.7003 - val_loss: 0.4661 - val_main_output_loss: 0.4432 - val_aux_output_loss: 0.6713\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4696 - main_output_loss: 0.4473 - aux_output_loss: 0.6704 - val_loss: 0.4580 - val_main_output_loss: 0.4370 - val_aux_output_loss: 0.6466\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4536 - main_output_loss: 0.4321 - aux_output_loss: 0.6476 - val_loss: 0.4500 - val_main_output_loss: 0.4301 - val_aux_output_loss: 0.6293\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4426 - main_output_loss: 0.4219 - aux_output_loss: 0.6293 - val_loss: 0.4344 - val_main_output_loss: 0.4148 - val_aux_output_loss: 0.6105\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4395 - main_output_loss: 0.4198 - aux_output_loss: 0.6161 - val_loss: 0.4387 - val_main_output_loss: 0.4204 - val_aux_output_loss: 0.6035\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4411 - main_output_loss: 0.4231 - aux_output_loss: 0.6026 - val_loss: 0.4277 - val_main_output_loss: 0.4099 - val_aux_output_loss: 0.5876\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4224 - main_output_loss: 0.4036 - aux_output_loss: 0.5913 - val_loss: 0.4175 - val_main_output_loss: 0.3998 - val_aux_output_loss: 0.5771\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4097 - main_output_loss: 0.3906 - aux_output_loss: 0.5812 - val_loss: 0.4056 - val_main_output_loss: 0.3881 - val_aux_output_loss: 0.5634\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4021 - main_output_loss: 0.3834 - aux_output_loss: 0.5701 - val_loss: 0.4012 - val_main_output_loss: 0.3842 - val_aux_output_loss: 0.5545\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3966 - main_output_loss: 0.3789 - aux_output_loss: 0.5559 - val_loss: 0.3973 - val_main_output_loss: 0.3811 - val_aux_output_loss: 0.5430\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3909 - main_output_loss: 0.3738 - aux_output_loss: 0.5453 - val_loss: 0.3897 - val_main_output_loss: 0.3735 - val_aux_output_loss: 0.5357\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3839 - main_output_loss: 0.3670 - aux_output_loss: 0.5358 - val_loss: 0.3893 - val_main_output_loss: 0.3739 - val_aux_output_loss: 0.5280\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3790 - main_output_loss: 0.3624 - aux_output_loss: 0.5287 - val_loss: 0.3858 - val_main_output_loss: 0.3707 - val_aux_output_loss: 0.5220\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3784 - main_output_loss: 0.3625 - aux_output_loss: 0.5215 - val_loss: 0.3820 - val_main_output_loss: 0.3670 - val_aux_output_loss: 0.5163\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3733 - main_output_loss: 0.3579 - aux_output_loss: 0.5123 - val_loss: 0.3720 - val_main_output_loss: 0.3573 - val_aux_output_loss: 0.5043\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    " [x_train_A, x_train_B], [y_train, y_train], epochs=20,\n",
    " validation_data=([x_valid_A, x_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7070dc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3699 - main_output_loss: 0.3536 - aux_output_loss: 0.5172\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    " [x_test_A, x_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "12e6ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([x_new_A, x_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "143daf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    " def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "     super().__init__(**kwargs) # handles standard args (e.g., name)\n",
    "     self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "     self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "     self.main_output = keras.layers.Dense(1)\n",
    "     self.aux_output = keras.layers.Dense(1)\n",
    " def call(self, inputs):\n",
    "     input_A, input_B = inputs\n",
    "     hidden1 = self.hidden1(input_B)\n",
    "     hidden2 = self.hidden2(hidden1)\n",
    "     concat = keras.layers.concatenate([input_A, hidden2])\n",
    "     main_output = self.main_output(concat)\n",
    "     aux_output = self.aux_output(hidden2)\n",
    "     return main_output, aux_output\n",
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "81bd5e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir():\n",
    " import time\n",
    " run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    " return os.path.join(root_logdir, run_id)\n",
    "run_logdir = get_run_logdir() # e.g., './my_logs/run_2019_06_07-15_15_22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1bb56cf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-542ed26f3435>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtensorboard_cb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_logdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history = model.fit(x_train, y_train, epochs=30,\n\u001b[0m\u001b[0;32m      3\u001b[0m  \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m  callbacks=[tensorboard_cb])\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2860\u001b[0m     \u001b[1;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2861\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2862\u001b[1;33m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[0;32m   2863\u001b[0m                          \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2864\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(x_train, y_train, epochs=30,\n",
    " validation_data=(x_valid, y_valid),\n",
    " callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "840cdb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    " for step in range(1, 1000 + 1):\n",
    "     tf.summary.scalar(\"my_scalar\", np.sin(step / 10), step=step)\n",
    "     data = (np.random.randn(100) + 2) * step / 100 # some random data\n",
    "     tf.summary.histogram(\"my_hist\", data, buckets=50, step=step)\n",
    "     images = np.random.rand(2, 32, 32, 3) # random 32×32 RGB images\n",
    "     tf.summary.image(\"my_images\", images * step / 1000, step=step)\n",
    "     texts = [\"The step is \" + str(step), \"Its square is \" + str(step**2)]\n",
    "     tf.summary.text(\"my_text\", texts, step=step)\n",
    "     sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
    "     audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "     tf.summary.audio(\"my_audio\", audio, sample_rate=48000, step=step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "071332fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    " model = keras.models.Sequential()\n",
    " model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    " for layer in range(n_hidden):\n",
    "     model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    " model.add(keras.layers.Dense(1))\n",
    " optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    " model.compile(loss=\"mse\", optimizer=optimizer)\n",
    " return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aff37380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-74-651c14c6d32f>:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
     ]
    }
   ],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "689b28a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.3952 - val_loss: 0.7449\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0863 - val_loss: 0.7117\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8153 - val_loss: 0.9442\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6196 - val_loss: 0.5923\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5668 - val_loss: 0.5618\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5421 - val_loss: 0.5444\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5233 - val_loss: 0.5201\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5062 - val_loss: 0.5066\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4956 - val_loss: 0.4974\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4855 - val_loss: 0.4901\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4884\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000027A1360FCA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(x_train, y_train, epochs=10,\n",
    " validation_data=(x_valid, y_valid),\n",
    " callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(x_test, y_test)\n",
    "y_pred = keras_reg.predict(x_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "04c6a60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.5211 - val_loss: 1.7155\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3325 - val_loss: 1.0688\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9376 - val_loss: 0.8786\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8301 - val_loss: 0.8104\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7737 - val_loss: 0.7687\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7412 - val_loss: 0.7396\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7165 - val_loss: 0.7168\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6974 - val_loss: 0.6982\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6801 - val_loss: 0.6814\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6652 - val_loss: 0.6670\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6511 - val_loss: 0.6533\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6389 - val_loss: 0.6423\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6275 - val_loss: 0.6302\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6166 - val_loss: 0.6198\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6067 - val_loss: 0.6107\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5961 - val_loss: 0.6043\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5865 - val_loss: 0.5920\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5789 - val_loss: 0.5848\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5701 - val_loss: 0.5757\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5636 - val_loss: 0.5693\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5555 - val_loss: 0.5621\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5492 - val_loss: 0.5571\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5428 - val_loss: 0.5514\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5371 - val_loss: 0.5456\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5317 - val_loss: 0.5401\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5265 - val_loss: 0.5365\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5215 - val_loss: 0.5305\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5169 - val_loss: 0.5268\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5123 - val_loss: 0.5217\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5084 - val_loss: 0.5188\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5044 - val_loss: 0.5167\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5010 - val_loss: 0.5122\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4971 - val_loss: 0.5102\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4930 - val_loss: 0.5045\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4904 - val_loss: 0.5011\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4883 - val_loss: 0.4997\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4853 - val_loss: 0.4986\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4828 - val_loss: 0.4955\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4795 - val_loss: 0.4915\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4776 - val_loss: 0.4891\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4755 - val_loss: 0.4870\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4731 - val_loss: 0.4844\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4715 - val_loss: 0.4830\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4692 - val_loss: 0.4843\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4665 - val_loss: 0.4790\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4658 - val_loss: 0.4781\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4636 - val_loss: 0.4781\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4621 - val_loss: 0.4747\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4605 - val_loss: 0.4738\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4590 - val_loss: 0.4718\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4574 - val_loss: 0.4708\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4562 - val_loss: 0.4693\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.454 - 1s 2ms/step - loss: 0.4549 - val_loss: 0.4701\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4531 - val_loss: 0.4664\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4520 - val_loss: 0.4651\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4513 - val_loss: 0.4655\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4496 - val_loss: 0.4661\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4487 - val_loss: 0.4622\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4475 - val_loss: 0.4622\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4470 - val_loss: 0.4612\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4452 - val_loss: 0.4606\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4449 - val_loss: 0.4588\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4431 - val_loss: 0.4564\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4429 - val_loss: 0.4562\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4418 - val_loss: 0.4555\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4405 - val_loss: 0.4539\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4399 - val_loss: 0.4552\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4393 - val_loss: 0.4554\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4377 - val_loss: 0.4514\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4375 - val_loss: 0.4511\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4368 - val_loss: 0.4524\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4356 - val_loss: 0.4495\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4348 - val_loss: 0.4523\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4345 - val_loss: 0.4484\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4331 - val_loss: 0.4473\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4325 - val_loss: 0.4463\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4315 - val_loss: 0.4466\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4309 - val_loss: 0.4450\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4300 - val_loss: 0.4443\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4289 - val_loss: 0.4432\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4282 - val_loss: 0.4422\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4277 - val_loss: 0.4421\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4270 - val_loss: 0.4416\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4263 - val_loss: 0.4402\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4256 - val_loss: 0.4397\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4250 - val_loss: 0.4389\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4244 - val_loss: 0.4393\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4237 - val_loss: 0.4377\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4233 - val_loss: 0.4371\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4225 - val_loss: 0.4375\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4219 - val_loss: 0.4357\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4216 - val_loss: 0.4356\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4210 - val_loss: 0.4349\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4203 - val_loss: 0.4358\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4200 - val_loss: 0.4337\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4192 - val_loss: 0.4343\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4191 - val_loss: 0.4330\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4185 - val_loss: 0.4323\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4180 - val_loss: 0.4320\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4174 - val_loss: 0.4321\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4127\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 3.6631 - val_loss: 1.6848\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2088 - val_loss: 0.9251\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8163 - val_loss: 0.7672\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7021 - val_loss: 0.7040\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6594 - val_loss: 0.6719\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6359 - val_loss: 0.6507\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6192 - val_loss: 0.6349\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6056 - val_loss: 0.6218\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5942 - val_loss: 0.6108\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5838 - val_loss: 0.6012\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5749 - val_loss: 0.5928\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5666 - val_loss: 0.5852\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5592 - val_loss: 0.5785\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5527 - val_loss: 0.5722\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5466 - val_loss: 0.5664\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5410 - val_loss: 0.5610\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5357 - val_loss: 0.5559\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5313 - val_loss: 0.5515\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5267 - val_loss: 0.5471\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5227 - val_loss: 0.5441\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5190 - val_loss: 0.5392\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5156 - val_loss: 0.5355\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5119 - val_loss: 0.5328\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5093 - val_loss: 0.5287\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5060 - val_loss: 0.5266\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5033 - val_loss: 0.5226\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5007 - val_loss: 0.5199\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4980 - val_loss: 0.5167\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4957 - val_loss: 0.5141\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4931 - val_loss: 0.5114\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4911 - val_loss: 0.5092\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4888 - val_loss: 0.5072\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4868 - val_loss: 0.5045\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4845 - val_loss: 0.5027\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4826 - val_loss: 0.5010\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4804 - val_loss: 0.4985\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4786 - val_loss: 0.4965\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4767 - val_loss: 0.4945\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4749 - val_loss: 0.4928\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4734 - val_loss: 0.4912\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4716 - val_loss: 0.4899\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4694 - val_loss: 0.4869\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4686 - val_loss: 0.4859\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4667 - val_loss: 0.4836\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4654 - val_loss: 0.4822\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4637 - val_loss: 0.4820\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4627 - val_loss: 0.4796\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4611 - val_loss: 0.4776\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4596 - val_loss: 0.4762\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4585 - val_loss: 0.4748\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4573 - val_loss: 0.4732\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4559 - val_loss: 0.4716\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4548 - val_loss: 0.4702\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4536 - val_loss: 0.4698\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4523 - val_loss: 0.4684\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4513 - val_loss: 0.4671\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4502 - val_loss: 0.4655\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4492 - val_loss: 0.4639\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4480 - val_loss: 0.4633\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4470 - val_loss: 0.4618\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4460 - val_loss: 0.4604\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4450 - val_loss: 0.4592\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4438 - val_loss: 0.4586\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4432 - val_loss: 0.4579\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4421 - val_loss: 0.4567\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4410 - val_loss: 0.4560\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4405 - val_loss: 0.4548\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4395 - val_loss: 0.4538\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4387 - val_loss: 0.4524\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4379 - val_loss: 0.4518\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4371 - val_loss: 0.4510\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4361 - val_loss: 0.4497\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4356 - val_loss: 0.4493\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4347 - val_loss: 0.4480\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4340 - val_loss: 0.4473\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4330 - val_loss: 0.4476\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4325 - val_loss: 0.4463\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4318 - val_loss: 0.4451\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4311 - val_loss: 0.4442\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4305 - val_loss: 0.4435\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4297 - val_loss: 0.4435\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4291 - val_loss: 0.4422\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4283 - val_loss: 0.4415\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4278 - val_loss: 0.4414\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4272 - val_loss: 0.4404\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4265 - val_loss: 0.4401\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4259 - val_loss: 0.4389\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4255 - val_loss: 0.4380\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4248 - val_loss: 0.4377\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4243 - val_loss: 0.4371\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4237 - val_loss: 0.4363\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4231 - val_loss: 0.4358\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4227 - val_loss: 0.4355\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4221 - val_loss: 0.4349\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4216 - val_loss: 0.4341\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4211 - val_loss: 0.4336\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4205 - val_loss: 0.4325\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4200 - val_loss: 0.4332\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4199 - val_loss: 0.4322\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4191 - val_loss: 0.4316\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4416\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 2.3369 - val_loss: 1.1490\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9301 - val_loss: 0.8438\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7621 - val_loss: 0.7620\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6982 - val_loss: 0.7185\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6632 - val_loss: 0.6895\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6400 - val_loss: 0.6685\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6227 - val_loss: 0.6518\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6090 - val_loss: 0.6385\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5977 - val_loss: 0.6273\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5879 - val_loss: 0.6171\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5798 - val_loss: 0.6085\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5722 - val_loss: 0.6008\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5655 - val_loss: 0.5941\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5594 - val_loss: 0.5876\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5536 - val_loss: 0.5815\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5484 - val_loss: 0.5759\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5433 - val_loss: 0.5712\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5389 - val_loss: 0.5657\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5345 - val_loss: 0.5607\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5306 - val_loss: 0.5566\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5268 - val_loss: 0.5528\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5232 - val_loss: 0.5491\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5199 - val_loss: 0.5455\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5167 - val_loss: 0.5420\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5137 - val_loss: 0.5389\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5108 - val_loss: 0.5359\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5080 - val_loss: 0.5326\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5052 - val_loss: 0.5301\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5026 - val_loss: 0.5274\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5000 - val_loss: 0.5245\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4976 - val_loss: 0.5214\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4952 - val_loss: 0.5189\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4930 - val_loss: 0.5166\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4906 - val_loss: 0.5148\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4887 - val_loss: 0.5121\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4865 - val_loss: 0.5102\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4845 - val_loss: 0.5079\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4826 - val_loss: 0.5061\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4808 - val_loss: 0.5037\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4790 - val_loss: 0.5020\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4772 - val_loss: 0.4999\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4755 - val_loss: 0.4983\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4739 - val_loss: 0.4967\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4721 - val_loss: 0.4952\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4706 - val_loss: 0.4937\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4692 - val_loss: 0.4911\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4675 - val_loss: 0.4892\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4662 - val_loss: 0.4881\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4647 - val_loss: 0.4867\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4634 - val_loss: 0.4855\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4620 - val_loss: 0.4832\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4606 - val_loss: 0.4823\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4593 - val_loss: 0.4806\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4580 - val_loss: 0.4794\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4568 - val_loss: 0.4786\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4555 - val_loss: 0.4765\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4543 - val_loss: 0.4751\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4531 - val_loss: 0.4742\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4520 - val_loss: 0.4733\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4508 - val_loss: 0.4715\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4497 - val_loss: 0.4704\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4487 - val_loss: 0.4694\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4475 - val_loss: 0.4681\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4466 - val_loss: 0.4675\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4454 - val_loss: 0.4660\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4446 - val_loss: 0.4651\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4435 - val_loss: 0.4642\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4424 - val_loss: 0.4635\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4411 - val_loss: 0.4619\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4403 - val_loss: 0.4618\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4395 - val_loss: 0.4601\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4386 - val_loss: 0.4596\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4377 - val_loss: 0.4589\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4369 - val_loss: 0.4585\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4360 - val_loss: 0.4572\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4352 - val_loss: 0.4562\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4344 - val_loss: 0.4553\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4336 - val_loss: 0.4547\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4327 - val_loss: 0.4543\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4321 - val_loss: 0.4533\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4313 - val_loss: 0.4525\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4306 - val_loss: 0.4519\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4299 - val_loss: 0.4517\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4294 - val_loss: 0.4504\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4285 - val_loss: 0.4493\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4280 - val_loss: 0.4492\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4275 - val_loss: 0.4485\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4267 - val_loss: 0.4477\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4261 - val_loss: 0.4474\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4255 - val_loss: 0.4463\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4250 - val_loss: 0.4459\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4243 - val_loss: 0.4455\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4238 - val_loss: 0.4453\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4232 - val_loss: 0.4452\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4225 - val_loss: 0.4433\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4221 - val_loss: 0.4427\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4215 - val_loss: 0.4423\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4210 - val_loss: 0.4422\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4205 - val_loss: 0.4413\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4200 - val_loss: 0.4403\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.4330\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 6.0889 - val_loss: 5.1276\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.6320 - val_loss: 3.9782\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.5916 - val_loss: 3.1402\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.8381 - val_loss: 2.5248\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.2889 - val_loss: 2.0700\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.8861 - val_loss: 1.7317\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.5878 - val_loss: 1.4790\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3659 - val_loss: 1.2889\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1998 - val_loss: 1.1456\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0749 - val_loss: 1.0370\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9806 - val_loss: 0.9543\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9089 - val_loss: 0.8910\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8541 - val_loss: 0.8423\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8119 - val_loss: 0.8045\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7792 - val_loss: 0.7751\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7537 - val_loss: 0.7520\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7335 - val_loss: 0.7335\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7175 - val_loss: 0.7187\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7045 - val_loss: 0.7066\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6939 - val_loss: 0.6967\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6851 - val_loss: 0.6884\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6777 - val_loss: 0.6814\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6714 - val_loss: 0.6754\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6659 - val_loss: 0.6701\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6611 - val_loss: 0.6655\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6568 - val_loss: 0.6613\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6529 - val_loss: 0.6575\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6493 - val_loss: 0.6541\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6460 - val_loss: 0.6508\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6429 - val_loss: 0.6478\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6400 - val_loss: 0.6450\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6373 - val_loss: 0.6422\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6347 - val_loss: 0.6397\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6322 - val_loss: 0.6372\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6298 - val_loss: 0.6348\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6274 - val_loss: 0.6325\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6252 - val_loss: 0.6302\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6230 - val_loss: 0.6281\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6209 - val_loss: 0.6260\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6188 - val_loss: 0.6239\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6168 - val_loss: 0.6220\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6149 - val_loss: 0.6201\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6130 - val_loss: 0.6182\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6112 - val_loss: 0.6163\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6094 - val_loss: 0.6145\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6076 - val_loss: 0.6128\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6059 - val_loss: 0.6110\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6042 - val_loss: 0.6093\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6025 - val_loss: 0.6077\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6009 - val_loss: 0.6061\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5994 - val_loss: 0.6045\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5978 - val_loss: 0.6030\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5963 - val_loss: 0.6015\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5949 - val_loss: 0.6000\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5934 - val_loss: 0.5986\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5920 - val_loss: 0.5972\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5907 - val_loss: 0.5958\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5893 - val_loss: 0.5944\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5880 - val_loss: 0.5930\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5867 - val_loss: 0.5917\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5855 - val_loss: 0.5905\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5843 - val_loss: 0.5892\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5831 - val_loss: 0.5880\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5819 - val_loss: 0.5869\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5807 - val_loss: 0.5857\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5796 - val_loss: 0.5846\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5785 - val_loss: 0.5835\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5774 - val_loss: 0.5824\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5764 - val_loss: 0.5813\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5753 - val_loss: 0.5803\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5743 - val_loss: 0.5792\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5734 - val_loss: 0.5782\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5724 - val_loss: 0.5773\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5714 - val_loss: 0.5763\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5705 - val_loss: 0.5754\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5696 - val_loss: 0.5744\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5687 - val_loss: 0.5735\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5679 - val_loss: 0.5726\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5670 - val_loss: 0.5717\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5662 - val_loss: 0.5709\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5654 - val_loss: 0.5701\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5646 - val_loss: 0.5693\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5638 - val_loss: 0.5684\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5631 - val_loss: 0.5677\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5623 - val_loss: 0.5669\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5616 - val_loss: 0.5661\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5609 - val_loss: 0.5654\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5602 - val_loss: 0.5647\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5595 - val_loss: 0.5639\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5588 - val_loss: 0.5632\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5582 - val_loss: 0.5626\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5575 - val_loss: 0.5619\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5569 - val_loss: 0.5612\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5563 - val_loss: 0.5605\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5557 - val_loss: 0.5600\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5551 - val_loss: 0.5594\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5545 - val_loss: 0.5588\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5540 - val_loss: 0.5582\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5534 - val_loss: 0.5576\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5529 - val_loss: 0.5571\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5511\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 7.0823 - val_loss: 5.9362\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5.4055 - val_loss: 4.6249\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 4.2020 - val_loss: 3.6618\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.3264 - val_loss: 2.9485\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.6838 - val_loss: 2.4189\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.2093 - val_loss: 2.0231\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8565 - val_loss: 1.7263\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5931 - val_loss: 1.5026\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.3953 - val_loss: 1.3334\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2461 - val_loss: 1.2046\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1330 - val_loss: 1.1064\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0468 - val_loss: 1.0309\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9806 - val_loss: 0.9722\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9293 - val_loss: 0.9264\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8891 - val_loss: 0.8902\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8573 - val_loss: 0.8613\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8318 - val_loss: 0.8379\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8112 - val_loss: 0.8188\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7943 - val_loss: 0.8030\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7801 - val_loss: 0.7897\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7681 - val_loss: 0.7784\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7578 - val_loss: 0.7686\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7487 - val_loss: 0.7600\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7407 - val_loss: 0.7524\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7334 - val_loss: 0.7454\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7268 - val_loss: 0.7390\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7207 - val_loss: 0.7332\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7150 - val_loss: 0.7278\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7097 - val_loss: 0.7226\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7047 - val_loss: 0.7178\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6999 - val_loss: 0.7132\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6954 - val_loss: 0.7089\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6910 - val_loss: 0.7047\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6868 - val_loss: 0.7007\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6827 - val_loss: 0.6967\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6789 - val_loss: 0.6929\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6751 - val_loss: 0.6893\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6715 - val_loss: 0.6857\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6679 - val_loss: 0.6823\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6645 - val_loss: 0.6789\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6611 - val_loss: 0.6756\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6579 - val_loss: 0.6724\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6547 - val_loss: 0.6694\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6517 - val_loss: 0.6663\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6487 - val_loss: 0.6633\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6458 - val_loss: 0.6604\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6430 - val_loss: 0.6575\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6402 - val_loss: 0.6548\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6375 - val_loss: 0.6520\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6348 - val_loss: 0.6494\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6323 - val_loss: 0.6468\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6298 - val_loss: 0.6443\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6273 - val_loss: 0.6417\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6249 - val_loss: 0.6394\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6226 - val_loss: 0.6370\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6203 - val_loss: 0.6347\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6181 - val_loss: 0.6324\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6160 - val_loss: 0.6302\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6139 - val_loss: 0.6281\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6118 - val_loss: 0.6259\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6098 - val_loss: 0.6239\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6078 - val_loss: 0.6218\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6059 - val_loss: 0.6199\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6041 - val_loss: 0.6179\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6022 - val_loss: 0.6160\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6005 - val_loss: 0.6141\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5987 - val_loss: 0.6124\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5970 - val_loss: 0.6106\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5954 - val_loss: 0.6089\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5938 - val_loss: 0.6071\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5922 - val_loss: 0.6055\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5906 - val_loss: 0.6039\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5891 - val_loss: 0.6023\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5876 - val_loss: 0.6007\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5862 - val_loss: 0.5992\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5848 - val_loss: 0.5977\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5834 - val_loss: 0.5962\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5821 - val_loss: 0.5948\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5808 - val_loss: 0.5934\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5795 - val_loss: 0.5920\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5783 - val_loss: 0.5907\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5770 - val_loss: 0.5894\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5759 - val_loss: 0.5881\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5747 - val_loss: 0.5868\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5736 - val_loss: 0.5856\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5724 - val_loss: 0.5844\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5714 - val_loss: 0.5832\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5703 - val_loss: 0.5821\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5693 - val_loss: 0.5810\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5683 - val_loss: 0.5799\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5673 - val_loss: 0.5788\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5663 - val_loss: 0.5777\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5653 - val_loss: 0.5767\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5644 - val_loss: 0.5757\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5635 - val_loss: 0.5747\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5627 - val_loss: 0.5737\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5618 - val_loss: 0.5728\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5609 - val_loss: 0.5718\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5601 - val_loss: 0.5709\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5593 - val_loss: 0.5700\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5684\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 6.3194 - val_loss: 5.5754\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.7410 - val_loss: 4.2237\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.6162 - val_loss: 3.2537\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.8068 - val_loss: 2.5514\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.2195 - val_loss: 2.0394\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.7906 - val_loss: 1.6640\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4755 - val_loss: 1.3872\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2430 - val_loss: 1.1822\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0706 - val_loss: 1.0298\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9424 - val_loss: 0.9161\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8469 - val_loss: 0.8311\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7754 - val_loss: 0.7673\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7219 - val_loss: 0.7192\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6816 - val_loss: 0.6828\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6512 - val_loss: 0.6552\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6282 - val_loss: 0.6342\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6107 - val_loss: 0.6181\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5973 - val_loss: 0.6057\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5871 - val_loss: 0.5963\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5792 - val_loss: 0.5888\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5730 - val_loss: 0.5829\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5682 - val_loss: 0.5783\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5644 - val_loss: 0.5746\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5614 - val_loss: 0.5716\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5590 - val_loss: 0.5693\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5569 - val_loss: 0.5673\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5553 - val_loss: 0.5656\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5539 - val_loss: 0.5643\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5527 - val_loss: 0.5630\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5516 - val_loss: 0.5618\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5507 - val_loss: 0.5609\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5499 - val_loss: 0.5601\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5490 - val_loss: 0.5593\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5484 - val_loss: 0.5586\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5477 - val_loss: 0.5580\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5471 - val_loss: 0.5573\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5466 - val_loss: 0.5567\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5460 - val_loss: 0.5562\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5455 - val_loss: 0.5556\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5450 - val_loss: 0.5550\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5445 - val_loss: 0.5546\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5440 - val_loss: 0.5541\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5436 - val_loss: 0.5536\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5431 - val_loss: 0.5531\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5427 - val_loss: 0.5527\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5423 - val_loss: 0.5522\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5419 - val_loss: 0.5518\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5415 - val_loss: 0.5513\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5410 - val_loss: 0.5510\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5407 - val_loss: 0.5505\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5403 - val_loss: 0.5502\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5399 - val_loss: 0.5497\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5396 - val_loss: 0.5493\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5392 - val_loss: 0.5489\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5388 - val_loss: 0.5486\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5385 - val_loss: 0.5482\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5381 - val_loss: 0.5478\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5378 - val_loss: 0.5475\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5374 - val_loss: 0.5472\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5371 - val_loss: 0.5468\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5368 - val_loss: 0.5465\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5365 - val_loss: 0.5461\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5362 - val_loss: 0.5458\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5359 - val_loss: 0.5455\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5356 - val_loss: 0.5453\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5353 - val_loss: 0.5450\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5350 - val_loss: 0.5447\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5347 - val_loss: 0.5443\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5344 - val_loss: 0.5440\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5342 - val_loss: 0.5437\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5339 - val_loss: 0.5434\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5336 - val_loss: 0.5431\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5334 - val_loss: 0.5428\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5331 - val_loss: 0.5425\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5329 - val_loss: 0.5423\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5326 - val_loss: 0.5420\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5324 - val_loss: 0.5417\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5321 - val_loss: 0.5414\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5319 - val_loss: 0.5411\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5317 - val_loss: 0.5409\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5313 - val_loss: 0.5406\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5312 - val_loss: 0.5404\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5310 - val_loss: 0.5402\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5308 - val_loss: 0.5399\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5306 - val_loss: 0.5397\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5304 - val_loss: 0.5395\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5302 - val_loss: 0.5394\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5299 - val_loss: 0.5391\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5297 - val_loss: 0.5389\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5296 - val_loss: 0.5387\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5294 - val_loss: 0.5385\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5292 - val_loss: 0.5383\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5290 - val_loss: 0.5381\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5288 - val_loss: 0.5378\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5286 - val_loss: 0.5377\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5285 - val_loss: 0.5375\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5283 - val_loss: 0.5373\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5281 - val_loss: 0.5372\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5279 - val_loss: 0.5369\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5277 - val_loss: 0.5367\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5664\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.8079 - val_loss: 0.6461\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.7396 - val_loss: 1.4138\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2716 - val_loss: 0.5688\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5953 - val_loss: 0.5252\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5008 - val_loss: 0.4955\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4821 - val_loss: 0.4718\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4627 - val_loss: 0.4559\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4454 - val_loss: 0.4446\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4369 - val_loss: 0.4402\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4288 - val_loss: 0.4276\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4210 - val_loss: 0.4243\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4161 - val_loss: 0.4161\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4098 - val_loss: 0.4131\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4068 - val_loss: 0.4120\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4033 - val_loss: 0.4048\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4009 - val_loss: 0.4060\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3975 - val_loss: 0.4036\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3955 - val_loss: 0.3972\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3930 - val_loss: 0.3971\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3915 - val_loss: 0.3961\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3904 - val_loss: 0.3922\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3879 - val_loss: 0.3899\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3865 - val_loss: 0.3896\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3852 - val_loss: 0.3871\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3832 - val_loss: 0.3853\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3813 - val_loss: 0.3865\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3802 - val_loss: 0.3876\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3797 - val_loss: 0.3828\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3783 - val_loss: 0.3824\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3766 - val_loss: 0.3830\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3761 - val_loss: 0.3804\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3751 - val_loss: 0.3773\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3729 - val_loss: 0.3764\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3724 - val_loss: 0.3791\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3718 - val_loss: 0.3792\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3704 - val_loss: 0.3769\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3698 - val_loss: 0.3714\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3686 - val_loss: 0.3730\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3684 - val_loss: 0.3719\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3675 - val_loss: 0.3728\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3660 - val_loss: 0.3682\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3649 - val_loss: 0.3672\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3641 - val_loss: 0.3669\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3633 - val_loss: 0.3657\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3615 - val_loss: 0.3704\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3619 - val_loss: 0.3642\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3598 - val_loss: 0.3650\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3593 - val_loss: 0.3656\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3582 - val_loss: 0.3652\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3587 - val_loss: 0.3610\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3578 - val_loss: 0.3613\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3568 - val_loss: 0.3626\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3565 - val_loss: 0.3597\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3558 - val_loss: 0.3604\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3546 - val_loss: 0.3613\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3534 - val_loss: 0.3582\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3528 - val_loss: 0.3587\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3535 - val_loss: 0.3577\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3526 - val_loss: 0.3562\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3521 - val_loss: 0.3596\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3510 - val_loss: 0.3560\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3504 - val_loss: 0.3561\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3499 - val_loss: 0.3594\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3497 - val_loss: 0.3584\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3486 - val_loss: 0.3550\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3483 - val_loss: 0.3564\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3479 - val_loss: 0.3542\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3475 - val_loss: 0.3568\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3475 - val_loss: 0.3552\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3466 - val_loss: 0.3556\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3461 - val_loss: 0.3520\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3456 - val_loss: 0.3515\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3458 - val_loss: 0.3547\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3451 - val_loss: 0.3506\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3446 - val_loss: 0.3533\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3434 - val_loss: 0.3554\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3441 - val_loss: 0.3503\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3431 - val_loss: 0.3512\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3420 - val_loss: 0.3539\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3424 - val_loss: 0.3512\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3417 - val_loss: 0.3482\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3419 - val_loss: 0.3470\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3404 - val_loss: 0.3576\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3410 - val_loss: 0.3469\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3400 - val_loss: 0.3469\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3393 - val_loss: 0.3479\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3398 - val_loss: 0.3463\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3381 - val_loss: 0.3514\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3388 - val_loss: 0.3475\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3386 - val_loss: 0.3457\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3372 - val_loss: 0.3447\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3382 - val_loss: 0.3522\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3377 - val_loss: 0.3461\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3368 - val_loss: 0.3467\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3367 - val_loss: 0.3461\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3362 - val_loss: 0.3441\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3358 - val_loss: 0.3423\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3357 - val_loss: 0.3433\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3353 - val_loss: 0.3460\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3353 - val_loss: 0.3445\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3371\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3047 - val_loss: 0.7119\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6484 - val_loss: 0.6300\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5810 - val_loss: 0.5681\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5350 - val_loss: 0.5338\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5226 - val_loss: 0.5105\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4937 - val_loss: 0.4956\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4797 - val_loss: 0.4907\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4666 - val_loss: 0.4756\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4615 - val_loss: 0.4681\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4552 - val_loss: 0.4607\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4462 - val_loss: 0.4572\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4406 - val_loss: 0.4525\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4392 - val_loss: 0.4452\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4326 - val_loss: 0.4428\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4353 - val_loss: 0.4416\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4262 - val_loss: 0.4386\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4232 - val_loss: 0.4323\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4189 - val_loss: 0.4327\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4159 - val_loss: 0.4280\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4128 - val_loss: 0.4232\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4102 - val_loss: 0.4242\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4182 - val_loss: 0.4402\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4083 - val_loss: 0.4251\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4039 - val_loss: 0.4178\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4008 - val_loss: 0.4214\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3984 - val_loss: 0.4138\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3973 - val_loss: 0.4091\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3944 - val_loss: 0.4105\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3931 - val_loss: 0.4061\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3908 - val_loss: 0.4043\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3888 - val_loss: 0.4029\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3871 - val_loss: 0.3991\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3873 - val_loss: 0.3987\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3837 - val_loss: 0.3990\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3822 - val_loss: 0.3966\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3798 - val_loss: 0.3962\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3784 - val_loss: 0.3976\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3799 - val_loss: 0.3904\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3764 - val_loss: 0.3927\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3749 - val_loss: 0.3945\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3730 - val_loss: 0.3899\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3719 - val_loss: 0.3885\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3748 - val_loss: 0.3900\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3713 - val_loss: 0.3866\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3715 - val_loss: 0.3844\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3689 - val_loss: 0.3841\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3662 - val_loss: 0.3832\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3656 - val_loss: 0.3838\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3637 - val_loss: 0.3820\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3632 - val_loss: 0.3868\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3624 - val_loss: 0.3781\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3620 - val_loss: 0.3890\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3684 - val_loss: 0.3850\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3593 - val_loss: 0.3747\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3584 - val_loss: 0.3746\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3575 - val_loss: 0.3756\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3619 - val_loss: 0.3735\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3552 - val_loss: 0.3739\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3575 - val_loss: 0.3727\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3551 - val_loss: 0.3704\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3527 - val_loss: 0.3695\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3522 - val_loss: 0.3721\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3521 - val_loss: 0.3717\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3524 - val_loss: 0.3689\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3517 - val_loss: 0.3667\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3504 - val_loss: 0.3726\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3486 - val_loss: 0.3703\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3499 - val_loss: 0.3701\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3473 - val_loss: 0.3662\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3471 - val_loss: 0.3648\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3493 - val_loss: 0.3635\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3614 - val_loss: 0.3846\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3471 - val_loss: 0.3621\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3433 - val_loss: 0.3651\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3468 - val_loss: 0.3783\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3444 - val_loss: 0.3640\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3413 - val_loss: 0.3640\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3425 - val_loss: 0.3615\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3429 - val_loss: 0.3637\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3400 - val_loss: 0.3590\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3421 - val_loss: 0.3603\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3397 - val_loss: 0.3701\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.3589\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3389 - val_loss: 0.3567\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3463 - val_loss: 0.3561\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3364 - val_loss: 0.3580\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3362 - val_loss: 0.3567\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3357 - val_loss: 0.3536\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3343 - val_loss: 0.3616\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4450 - val_loss: 0.3569\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3408 - val_loss: 0.3819\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3383 - val_loss: 0.3572\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3342 - val_loss: 0.3557\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3329 - val_loss: 0.3530\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3320 - val_loss: 0.3532\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3314 - val_loss: 0.3501\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3327 - val_loss: 0.3664\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3420 - val_loss: 0.3586\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3330 - val_loss: 0.3485\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3316 - val_loss: 0.3493\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3598\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.5176 - val_loss: 0.6846\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6529 - val_loss: 0.6180\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5739 - val_loss: 0.5680\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5336 - val_loss: 0.5362\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5079 - val_loss: 0.5169\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4905 - val_loss: 0.4997\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4778 - val_loss: 0.4877\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4673 - val_loss: 0.4792\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4590 - val_loss: 0.4706\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4522 - val_loss: 0.4660\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4457 - val_loss: 0.4573\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4401 - val_loss: 0.4536\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4358 - val_loss: 0.4494\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4315 - val_loss: 0.4428\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4272 - val_loss: 0.4410\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4240 - val_loss: 0.4360\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4205 - val_loss: 0.4321\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4170 - val_loss: 0.4304\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4144 - val_loss: 0.4313\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4116 - val_loss: 0.4251\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4081 - val_loss: 0.4200\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4066 - val_loss: 0.4193\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4044 - val_loss: 0.4189\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4018 - val_loss: 0.4195\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4000 - val_loss: 0.4151\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3983 - val_loss: 0.4101\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3968 - val_loss: 0.4086\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3945 - val_loss: 0.4063\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3928 - val_loss: 0.4055\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3907 - val_loss: 0.4123\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3888 - val_loss: 0.4056\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3879 - val_loss: 0.4044\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3872 - val_loss: 0.3998\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3850 - val_loss: 0.3976\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3841 - val_loss: 0.3982\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3826 - val_loss: 0.3987\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3813 - val_loss: 0.3982\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3803 - val_loss: 0.3942\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3781 - val_loss: 0.3929\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3767 - val_loss: 0.3926\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3758 - val_loss: 0.3885\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3749 - val_loss: 0.3894\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3734 - val_loss: 0.3874\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3733 - val_loss: 0.3926\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3731 - val_loss: 0.3895\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3699 - val_loss: 0.3875\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3724 - val_loss: 0.3852\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3731 - val_loss: 0.3831\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3677 - val_loss: 0.3808\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3666 - val_loss: 0.4013\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3661 - val_loss: 0.3802\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3649 - val_loss: 0.3795\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3633 - val_loss: 0.3809\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3624 - val_loss: 0.3774\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3609 - val_loss: 0.3774\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3621 - val_loss: 0.3770\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3618 - val_loss: 0.3750\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3591 - val_loss: 0.3735\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3589 - val_loss: 0.3749\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.3734\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3565 - val_loss: 0.3732\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3559 - val_loss: 0.3768\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3557 - val_loss: 0.3901\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3575 - val_loss: 0.3692\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3566 - val_loss: 0.3718\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3546 - val_loss: 0.3695\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3533 - val_loss: 0.3807\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3520 - val_loss: 0.3698\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3510 - val_loss: 0.3679\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3533 - val_loss: 0.3680\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3507 - val_loss: 0.3694\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3498 - val_loss: 0.3687\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3490 - val_loss: 0.3645\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3482 - val_loss: 0.3700\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3461 - val_loss: 0.3660\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3474 - val_loss: 0.3637\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3455 - val_loss: 0.3657\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3454 - val_loss: 0.3676\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3451 - val_loss: 0.3609\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3467 - val_loss: 0.3587\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3465 - val_loss: 0.3734\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3463 - val_loss: 0.3608\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3500 - val_loss: 0.3604\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3452 - val_loss: 0.3568\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3419 - val_loss: 0.3594\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3484 - val_loss: 0.3728\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3512 - val_loss: 0.3604\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3473 - val_loss: 0.3614\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3422 - val_loss: 0.3576\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3399 - val_loss: 0.3596\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3411 - val_loss: 0.3570\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3393 - val_loss: 0.3547\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3381 - val_loss: 0.3552\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3393 - val_loss: 0.3558\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3395 - val_loss: 0.3565\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3370 - val_loss: 0.3592\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3376 - val_loss: 0.3522\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3363 - val_loss: 0.3784\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3358 - val_loss: 0.3543\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3353 - val_loss: 0.3586\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3613\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.4030 - val_loss: 0.7903\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7163 - val_loss: 0.6731\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6739 - val_loss: 0.6257\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7231 - val_loss: 0.5633\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9079 - val_loss: 0.5785\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7798 - val_loss: 0.5321\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5435 - val_loss: 0.5198\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5049 - val_loss: 0.5007\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4904 - val_loss: 0.4936\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4819 - val_loss: 0.4836\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4717 - val_loss: 0.4733\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4660 - val_loss: 0.4688\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4601 - val_loss: 0.4650\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4541 - val_loss: 0.4601\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4495 - val_loss: 0.4550\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4477 - val_loss: 0.4548\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4430 - val_loss: 0.4490\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4419 - val_loss: 0.4459\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4371 - val_loss: 0.4423\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4344 - val_loss: 0.4401\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4311 - val_loss: 0.4393\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4285 - val_loss: 0.4349\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4271 - val_loss: 0.4320\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4243 - val_loss: 0.4306\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4224 - val_loss: 0.4288\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4201 - val_loss: 0.4261\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4175 - val_loss: 0.4270\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4184 - val_loss: 0.4247\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4156 - val_loss: 0.4203\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4127 - val_loss: 0.4190\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4104 - val_loss: 0.4172\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4082 - val_loss: 0.4151\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4077 - val_loss: 0.4133\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4052 - val_loss: 0.4122\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4038 - val_loss: 0.4108\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4019 - val_loss: 0.4130\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4011 - val_loss: 0.4089\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3991 - val_loss: 0.4066\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3978 - val_loss: 0.4052\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3959 - val_loss: 0.4079\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3952 - val_loss: 0.4044\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3952 - val_loss: 0.4039\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3950 - val_loss: 0.4027\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3913 - val_loss: 0.3998\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3904 - val_loss: 0.4002\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3891 - val_loss: 0.3969\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3884 - val_loss: 0.3958\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3868 - val_loss: 0.3942\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3858 - val_loss: 0.3935\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3852 - val_loss: 0.3952\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3837 - val_loss: 0.3917\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3830 - val_loss: 0.3922\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3813 - val_loss: 0.3909\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3797 - val_loss: 0.3912\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3817 - val_loss: 0.3915\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3791 - val_loss: 0.3870\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3789 - val_loss: 0.3867\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3764 - val_loss: 0.3887\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3759 - val_loss: 0.3888\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3756 - val_loss: 0.3864\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3742 - val_loss: 0.3861\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3735 - val_loss: 0.3823\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3731 - val_loss: 0.3844\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3722 - val_loss: 0.3817\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3711 - val_loss: 0.3806\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3705 - val_loss: 0.3810\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3695 - val_loss: 0.3792\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3693 - val_loss: 0.3796\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3672 - val_loss: 0.3794\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3692 - val_loss: 0.3789\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3678 - val_loss: 0.3776\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3661 - val_loss: 0.3758\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3655 - val_loss: 0.3791\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3652 - val_loss: 0.3752\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3648 - val_loss: 0.3754\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3637 - val_loss: 0.3757\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3630 - val_loss: 0.3762\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3643 - val_loss: 0.3769\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3640 - val_loss: 0.3745\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3621 - val_loss: 0.3737\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3635 - val_loss: 0.3715\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3609 - val_loss: 0.3727\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3603 - val_loss: 0.3723\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3611 - val_loss: 0.3707\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3599 - val_loss: 0.3716\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3595 - val_loss: 0.3712\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3593 - val_loss: 0.3790\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3596 - val_loss: 0.3696\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3581 - val_loss: 0.3709\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3623 - val_loss: 0.3666\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3593 - val_loss: 0.3675\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3604 - val_loss: 0.3801\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3598 - val_loss: 0.3706\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3628 - val_loss: 0.3659\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3628 - val_loss: 0.3688\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3595 - val_loss: 0.3653\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3538 - val_loss: 0.3654\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3529 - val_loss: 0.3644\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3528 - val_loss: 0.3645\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3529 - val_loss: 0.3628\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3507\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2354 - val_loss: 0.7172\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6577 - val_loss: 0.6398\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5908 - val_loss: 0.5986\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5598 - val_loss: 0.5614\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5296 - val_loss: 0.5378\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5121 - val_loss: 0.5211\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4980 - val_loss: 0.5128\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4866 - val_loss: 0.4979\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4821 - val_loss: 0.4889\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4717 - val_loss: 0.4817\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4653 - val_loss: 0.4772\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4617 - val_loss: 0.4733\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4557 - val_loss: 0.4681\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4523 - val_loss: 0.4631\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4477 - val_loss: 0.4616\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4441 - val_loss: 0.4564\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4413 - val_loss: 0.4554\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4384 - val_loss: 0.4532\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4352 - val_loss: 0.4493\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4329 - val_loss: 0.4463\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4307 - val_loss: 0.4445\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4287 - val_loss: 0.4436\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4265 - val_loss: 0.4413\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4243 - val_loss: 0.4403\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4223 - val_loss: 0.4382\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4205 - val_loss: 0.4392\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4189 - val_loss: 0.4346\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4180 - val_loss: 0.4317\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4152 - val_loss: 0.4328\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4135 - val_loss: 0.4290\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4118 - val_loss: 0.4284\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4114 - val_loss: 0.4278\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4110 - val_loss: 0.4257\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4071 - val_loss: 0.4224\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4057 - val_loss: 0.4243\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4039 - val_loss: 0.4235\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4026 - val_loss: 0.4198\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4010 - val_loss: 0.4181\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3996 - val_loss: 0.4200\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3982 - val_loss: 0.4170\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3970 - val_loss: 0.4139\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3955 - val_loss: 0.4127\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3942 - val_loss: 0.4111\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3929 - val_loss: 0.4168\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3914 - val_loss: 0.4126\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3905 - val_loss: 0.4084\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3887 - val_loss: 0.4057\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3881 - val_loss: 0.4063\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3860 - val_loss: 0.4056\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3854 - val_loss: 0.4056\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3832 - val_loss: 0.4048\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3831 - val_loss: 0.4019\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3824 - val_loss: 0.4010\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3802 - val_loss: 0.3997\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3824 - val_loss: 0.3998\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3922 - val_loss: 0.3999\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3794 - val_loss: 0.3972\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3761 - val_loss: 0.4027\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3754 - val_loss: 0.3952\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3744 - val_loss: 0.3980\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3730 - val_loss: 0.3935\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3722 - val_loss: 0.3934\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3710 - val_loss: 0.3913\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3697 - val_loss: 0.3890\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3688 - val_loss: 0.3890\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3678 - val_loss: 0.3899\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3665 - val_loss: 0.3871\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3656 - val_loss: 0.3855\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3660 - val_loss: 0.3865\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3668 - val_loss: 0.3856\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3630 - val_loss: 0.3878\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3642 - val_loss: 0.3879\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3651 - val_loss: 0.3846\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3618 - val_loss: 0.3857\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3601 - val_loss: 0.3824\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3594 - val_loss: 0.3807\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3593 - val_loss: 0.3805\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3577 - val_loss: 0.3797\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3577 - val_loss: 0.3792\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3574 - val_loss: 0.3846\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3570 - val_loss: 0.3788\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3552 - val_loss: 0.3778\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3550 - val_loss: 0.3771\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3543 - val_loss: 0.3757\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3528 - val_loss: 0.3770\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3540 - val_loss: 0.3757\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3527 - val_loss: 0.3794\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3511 - val_loss: 0.3765\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3505 - val_loss: 0.3740\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3498 - val_loss: 0.3733\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3499 - val_loss: 0.3731\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3487 - val_loss: 0.3737\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3487 - val_loss: 0.3734\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3483 - val_loss: 0.3773\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3537 - val_loss: 0.3798\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3471 - val_loss: 0.3735\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3464 - val_loss: 0.3762\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3459 - val_loss: 0.3747\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3494 - val_loss: 0.3738\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3450 - val_loss: 0.3703\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3687\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2130 - val_loss: 0.6713\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1168 - val_loss: 0.6665\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7740 - val_loss: 0.5842\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5629 - val_loss: 0.5536\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5295 - val_loss: 0.5347\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5109 - val_loss: 0.5185\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.498 - 1s 2ms/step - loss: 0.4987 - val_loss: 0.5061\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4886 - val_loss: 0.4978\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4802 - val_loss: 0.4886\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4736 - val_loss: 0.4842\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4676 - val_loss: 0.4784\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4623 - val_loss: 0.4710\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4571 - val_loss: 0.4659\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4529 - val_loss: 0.4616\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4489 - val_loss: 0.4611\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4451 - val_loss: 0.4568\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4423 - val_loss: 0.4522\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4386 - val_loss: 0.4460\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4357 - val_loss: 0.4450\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4329 - val_loss: 0.4406\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4302 - val_loss: 0.4406\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4284 - val_loss: 0.4391\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4249 - val_loss: 0.4351\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4235 - val_loss: 0.4339\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4221 - val_loss: 0.4317\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4191 - val_loss: 0.4293\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4171 - val_loss: 0.4285\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4153 - val_loss: 0.4263\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4128 - val_loss: 0.4261\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4112 - val_loss: 0.4254\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4099 - val_loss: 0.4226\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4082 - val_loss: 0.4186\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4067 - val_loss: 0.4210\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4048 - val_loss: 0.4178\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4040 - val_loss: 0.4164\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4019 - val_loss: 0.4157\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4010 - val_loss: 0.4115\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3993 - val_loss: 0.4118\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3985 - val_loss: 0.4110\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3979 - val_loss: 0.4131\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3958 - val_loss: 0.4066\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3946 - val_loss: 0.4045\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3927 - val_loss: 0.4087\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3908 - val_loss: 0.4091\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3902 - val_loss: 0.4016\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3893 - val_loss: 0.4022\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3881 - val_loss: 0.4028\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3869 - val_loss: 0.4022\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3865 - val_loss: 0.3985\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3853 - val_loss: 0.3994\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3837 - val_loss: 0.3977\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3836 - val_loss: 0.3991\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3819 - val_loss: 0.3967\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3808 - val_loss: 0.3935\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3806 - val_loss: 0.3936\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3789 - val_loss: 0.3951\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3783 - val_loss: 0.3918\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3771 - val_loss: 0.3906\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3779 - val_loss: 0.3897\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3754 - val_loss: 0.3898\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3743 - val_loss: 0.3897\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3736 - val_loss: 0.3876\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3722 - val_loss: 0.3908\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3711 - val_loss: 0.3893\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3721 - val_loss: 0.3859\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3700 - val_loss: 0.3869\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3695 - val_loss: 0.3857\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3681 - val_loss: 0.3836\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3672 - val_loss: 0.3846\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3686 - val_loss: 0.3820\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3658 - val_loss: 0.3826\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3647 - val_loss: 0.3806\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3650 - val_loss: 0.3822\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3644 - val_loss: 0.3824\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3641 - val_loss: 0.3819\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3636 - val_loss: 0.3791\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3615 - val_loss: 0.3786\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3611 - val_loss: 0.3791\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3624 - val_loss: 0.3799\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3626 - val_loss: 0.3794\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3583 - val_loss: 0.3786\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3595 - val_loss: 0.3748\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3591 - val_loss: 0.3755\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.3791\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3558 - val_loss: 0.3732\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3567 - val_loss: 0.3737\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3582 - val_loss: 0.3734\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3584 - val_loss: 0.3730\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3577 - val_loss: 0.3748\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3545 - val_loss: 0.3728\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3535 - val_loss: 0.3693\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3525 - val_loss: 0.3703\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3536 - val_loss: 0.3749\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3529 - val_loss: 0.3717\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3523 - val_loss: 0.3710\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3508 - val_loss: 0.3700\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3520 - val_loss: 0.3694\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3520 - val_loss: 0.3707\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3486 - val_loss: 0.3698\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3494 - val_loss: 0.3672\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3685\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 3.1230 - val_loss: 1.6238\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2439 - val_loss: 0.9661\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8866 - val_loss: 0.8113\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7797 - val_loss: 0.7589\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7403 - val_loss: 0.7321\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7194 - val_loss: 0.7145\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7037 - val_loss: 0.6996\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6899 - val_loss: 0.6867\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6775 - val_loss: 0.6751\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6657 - val_loss: 0.6642\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6547 - val_loss: 0.6540\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6447 - val_loss: 0.6446\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6348 - val_loss: 0.6357\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6257 - val_loss: 0.6272\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6170 - val_loss: 0.6191\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6088 - val_loss: 0.6114\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6010 - val_loss: 0.6043\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5937 - val_loss: 0.5972\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5866 - val_loss: 0.5908\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5801 - val_loss: 0.5847\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5738 - val_loss: 0.5787\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5679 - val_loss: 0.5732\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5622 - val_loss: 0.5680\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5568 - val_loss: 0.5629\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5520 - val_loss: 0.5582\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5471 - val_loss: 0.5537\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5427 - val_loss: 0.5495\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5384 - val_loss: 0.5457\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5345 - val_loss: 0.5420\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5306 - val_loss: 0.5384\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5272 - val_loss: 0.5348\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5237 - val_loss: 0.5318\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5207 - val_loss: 0.5288\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5176 - val_loss: 0.5259\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5147 - val_loss: 0.5231\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5121 - val_loss: 0.5206\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5096 - val_loss: 0.5182\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5072 - val_loss: 0.5158\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5049 - val_loss: 0.5136\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5028 - val_loss: 0.5115\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5007 - val_loss: 0.5098\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4987 - val_loss: 0.5081\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4969 - val_loss: 0.5059\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4952 - val_loss: 0.5042\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4934 - val_loss: 0.5026\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4918 - val_loss: 0.5010\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4903 - val_loss: 0.4995\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4888 - val_loss: 0.4981\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4874 - val_loss: 0.4966\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4860 - val_loss: 0.4952\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4848 - val_loss: 0.4941\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4835 - val_loss: 0.4926\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4823 - val_loss: 0.4914\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4812 - val_loss: 0.4903\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4800 - val_loss: 0.4892\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4789 - val_loss: 0.4882\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4779 - val_loss: 0.4871\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4770 - val_loss: 0.4860\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4759 - val_loss: 0.4850\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4749 - val_loss: 0.4840\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4741 - val_loss: 0.4831\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4732 - val_loss: 0.4824\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4723 - val_loss: 0.4812\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4714 - val_loss: 0.4803\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4706 - val_loss: 0.4797\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4699 - val_loss: 0.4791\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4691 - val_loss: 0.4783\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4683 - val_loss: 0.4775\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4675 - val_loss: 0.4766\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4667 - val_loss: 0.4757\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4661 - val_loss: 0.4752\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4653 - val_loss: 0.4745\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4646 - val_loss: 0.4739\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4639 - val_loss: 0.4732\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4632 - val_loss: 0.4723\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4625 - val_loss: 0.4717\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4618 - val_loss: 0.4710\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4612 - val_loss: 0.4704\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4605 - val_loss: 0.4699\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4599 - val_loss: 0.4692\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4593 - val_loss: 0.4688\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4587 - val_loss: 0.4681\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4581 - val_loss: 0.4675\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4575 - val_loss: 0.4671\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4570 - val_loss: 0.4665\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4563 - val_loss: 0.4659\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4557 - val_loss: 0.4653\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4552 - val_loss: 0.4650\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4547 - val_loss: 0.4643\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4542 - val_loss: 0.4636\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4536 - val_loss: 0.4631\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4531 - val_loss: 0.4625\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4526 - val_loss: 0.4620\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4521 - val_loss: 0.4617\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4516 - val_loss: 0.4611\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4510 - val_loss: 0.4606\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4506 - val_loss: 0.4603\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4501 - val_loss: 0.4596\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4496 - val_loss: 0.4590\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4491 - val_loss: 0.4589\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4462\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 3.5247 - val_loss: 1.8831\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3638 - val_loss: 1.0463\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9025 - val_loss: 0.8302\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7599 - val_loss: 0.7502\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7007 - val_loss: 0.7092\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6696 - val_loss: 0.6844\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6495 - val_loss: 0.6666\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6342 - val_loss: 0.6521\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6218 - val_loss: 0.6394\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6104 - val_loss: 0.6282\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6007 - val_loss: 0.6180\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5914 - val_loss: 0.6085\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5829 - val_loss: 0.6001\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5748 - val_loss: 0.5918\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5674 - val_loss: 0.5845\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5605 - val_loss: 0.5776\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5539 - val_loss: 0.5709\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5479 - val_loss: 0.5645\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5424 - val_loss: 0.5590\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5371 - val_loss: 0.5535\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5323 - val_loss: 0.5485\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5279 - val_loss: 0.5443\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5237 - val_loss: 0.5399\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5197 - val_loss: 0.5356\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5160 - val_loss: 0.5316\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5125 - val_loss: 0.5279\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5093 - val_loss: 0.5249\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5062 - val_loss: 0.5219\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5033 - val_loss: 0.5191\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5006 - val_loss: 0.5163\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4979 - val_loss: 0.5133\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4955 - val_loss: 0.5107\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4931 - val_loss: 0.5081\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4910 - val_loss: 0.5064\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4890 - val_loss: 0.5044\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4870 - val_loss: 0.5024\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4850 - val_loss: 0.5002\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4835 - val_loss: 0.4987\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4817 - val_loss: 0.4969\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4802 - val_loss: 0.4955\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4786 - val_loss: 0.4934\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4774 - val_loss: 0.4925\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4760 - val_loss: 0.4908\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4746 - val_loss: 0.4895\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4735 - val_loss: 0.4883\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4723 - val_loss: 0.4868\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4711 - val_loss: 0.4859\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4700 - val_loss: 0.4849\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4690 - val_loss: 0.4841\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4680 - val_loss: 0.4829\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4670 - val_loss: 0.4821\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4661 - val_loss: 0.4812\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4652 - val_loss: 0.4802\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4642 - val_loss: 0.4790\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4635 - val_loss: 0.4780\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4626 - val_loss: 0.4776\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4618 - val_loss: 0.4769\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4609 - val_loss: 0.4758\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4602 - val_loss: 0.4749\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4595 - val_loss: 0.4745\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4588 - val_loss: 0.4737\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4580 - val_loss: 0.4731\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4573 - val_loss: 0.4725\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4567 - val_loss: 0.4719\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4560 - val_loss: 0.4709\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4554 - val_loss: 0.4702\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4547 - val_loss: 0.4696\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4541 - val_loss: 0.4692\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4535 - val_loss: 0.4685\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4529 - val_loss: 0.4678\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4523 - val_loss: 0.4671\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4518 - val_loss: 0.4666\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4512 - val_loss: 0.4663\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4507 - val_loss: 0.4656\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4501 - val_loss: 0.4651\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4497 - val_loss: 0.4647\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4491 - val_loss: 0.4642\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4486 - val_loss: 0.4636\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4481 - val_loss: 0.4630\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4477 - val_loss: 0.4627\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4471 - val_loss: 0.4623\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4467 - val_loss: 0.4618\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4462 - val_loss: 0.4613\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4457 - val_loss: 0.4607\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4453 - val_loss: 0.4606\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4448 - val_loss: 0.4599\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4444 - val_loss: 0.4596\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4439 - val_loss: 0.4588\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4434 - val_loss: 0.4585\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4429 - val_loss: 0.4584\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4426 - val_loss: 0.4576\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4421 - val_loss: 0.4573\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4417 - val_loss: 0.4569\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4413 - val_loss: 0.4566\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4409 - val_loss: 0.4562\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4404 - val_loss: 0.4559\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4400 - val_loss: 0.4552\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4396 - val_loss: 0.4546\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4393 - val_loss: 0.4544\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4388 - val_loss: 0.4541\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4574\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 2.7512 - val_loss: 1.7414\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4150 - val_loss: 1.1419\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0089 - val_loss: 0.9197\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8464 - val_loss: 0.8281\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7735 - val_loss: 0.7825\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7366 - val_loss: 0.7560\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7133 - val_loss: 0.7371\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6962 - val_loss: 0.7211\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6815 - val_loss: 0.7068\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6682 - val_loss: 0.6938\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6560 - val_loss: 0.6812\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6444 - val_loss: 0.6694\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6335 - val_loss: 0.6581\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6230 - val_loss: 0.6473\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6132 - val_loss: 0.6372\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6036 - val_loss: 0.6272\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5948 - val_loss: 0.6177\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5862 - val_loss: 0.6086\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5780 - val_loss: 0.6002\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5702 - val_loss: 0.5923\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5629 - val_loss: 0.5844\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5559 - val_loss: 0.5771\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5494 - val_loss: 0.5700\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5431 - val_loss: 0.5632\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5371 - val_loss: 0.5573\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5315 - val_loss: 0.5512\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5262 - val_loss: 0.5456\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5213 - val_loss: 0.5404\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5167 - val_loss: 0.5355\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5123 - val_loss: 0.5311\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5084 - val_loss: 0.5266\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5045 - val_loss: 0.5228\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5010 - val_loss: 0.5190\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4976 - val_loss: 0.5153\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4945 - val_loss: 0.5119\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4917 - val_loss: 0.5087\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4890 - val_loss: 0.5060\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4864 - val_loss: 0.5033\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4841 - val_loss: 0.5005\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4818 - val_loss: 0.4981\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4797 - val_loss: 0.4959\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4778 - val_loss: 0.4939\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4759 - val_loss: 0.4917\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4741 - val_loss: 0.4897\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.475 - 1s 2ms/step - loss: 0.4724 - val_loss: 0.4881\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4708 - val_loss: 0.4860\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4692 - val_loss: 0.4847\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4677 - val_loss: 0.4833\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4665 - val_loss: 0.4815\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4650 - val_loss: 0.4799\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4639 - val_loss: 0.4788\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4626 - val_loss: 0.4776\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4615 - val_loss: 0.4764\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4604 - val_loss: 0.4752\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4593 - val_loss: 0.4740\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4582 - val_loss: 0.4733\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4572 - val_loss: 0.4723\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4563 - val_loss: 0.4712\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4553 - val_loss: 0.4698\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4545 - val_loss: 0.4690\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4536 - val_loss: 0.4682\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4527 - val_loss: 0.4673\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4519 - val_loss: 0.4665\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4510 - val_loss: 0.4654\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4503 - val_loss: 0.4645\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4495 - val_loss: 0.4636\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4488 - val_loss: 0.4634\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4481 - val_loss: 0.4621\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4473 - val_loss: 0.4617\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4466 - val_loss: 0.4611\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4459 - val_loss: 0.4602\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4452 - val_loss: 0.4593\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4444 - val_loss: 0.4584\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4439 - val_loss: 0.4582\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4432 - val_loss: 0.4578\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4426 - val_loss: 0.4567\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4420 - val_loss: 0.4562\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4414 - val_loss: 0.4555\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4407 - val_loss: 0.4550\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4402 - val_loss: 0.4544\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4395 - val_loss: 0.4541\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4389 - val_loss: 0.4533\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4384 - val_loss: 0.4526\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4378 - val_loss: 0.4525\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4373 - val_loss: 0.4518\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4367 - val_loss: 0.4510\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4362 - val_loss: 0.4506\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4356 - val_loss: 0.4499\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4351 - val_loss: 0.4498\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4346 - val_loss: 0.4493\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4341 - val_loss: 0.4485\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4335 - val_loss: 0.4484\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4330 - val_loss: 0.4477\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4325 - val_loss: 0.4472\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4320 - val_loss: 0.4469\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4316 - val_loss: 0.4464\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4310 - val_loss: 0.4459\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4306 - val_loss: 0.4458\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4301 - val_loss: 0.4446\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4297 - val_loss: 0.4442\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4450\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 2.9962 - val_loss: 0.8649\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.9425 - val_loss: 0.7326\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.2239 - val_loss: 0.6240\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.5100 - val_loss: 0.8062\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.7550 - val_loss: 0.6022\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 12.0659 - val_loss: 0.9321\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 16.9041 - val_loss: 0.7557\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 36.5861 - val_loss: 1.2269\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 62.5277 - val_loss: 1.2244\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 109.6429 - val_loss: 2.8091\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 190.2038 - val_loss: 3.8659\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 269.5600 - val_loss: 12.2467\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 591.7084 - val_loss: 8.1935\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1055.6022 - val_loss: 16.0481\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1830.6549 - val_loss: 26.7864\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1025.5820\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 2.1479 - val_loss: 0.8819\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7542 - val_loss: 0.7091\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6678 - val_loss: 0.6600\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6293 - val_loss: 0.6271\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6038 - val_loss: 0.6042\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5853 - val_loss: 0.5843\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5678 - val_loss: 0.5718\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5601 - val_loss: 0.5618\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5510 - val_loss: 0.5581\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5443 - val_loss: 0.5474\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5443 - val_loss: 0.5442\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5412 - val_loss: 0.5426\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5311 - val_loss: 0.5355\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5418 - val_loss: 0.5365\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5329 - val_loss: 0.5481\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5404 - val_loss: 0.5492\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5446 - val_loss: 0.5386\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5412 - val_loss: 0.5487\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5473 - val_loss: 0.5377\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5381 - val_loss: 0.5430\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5352 - val_loss: 0.5507\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5379 - val_loss: 0.5509\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5445 - val_loss: 0.5367\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5357\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.9330 - val_loss: 0.7059\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6277 - val_loss: 0.5907\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5927 - val_loss: 0.5822\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5820 - val_loss: 0.5568\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5626 - val_loss: 0.5535\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5515 - val_loss: 0.5446\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5388 - val_loss: 0.5418\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5340 - val_loss: 0.5369\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5333 - val_loss: 0.5378\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5306 - val_loss: 0.5327\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5269 - val_loss: 0.5305\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5239 - val_loss: 0.5325\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5239 - val_loss: 0.5291\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5227 - val_loss: 0.5265\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5221 - val_loss: 0.5272\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5218 - val_loss: 0.5257\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5203 - val_loss: 0.5273\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5208 - val_loss: 0.5258\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5193 - val_loss: 0.5271\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5222 - val_loss: 0.5226\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5311 - val_loss: 0.5272\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5222 - val_loss: 0.5220\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5305 - val_loss: 0.5259\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5233 - val_loss: 0.5213\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5264 - val_loss: 0.5268\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5224 - val_loss: 0.5219\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5281 - val_loss: 0.5257\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5248 - val_loss: 0.5240\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5211 - val_loss: 0.5277\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5187 - val_loss: 0.5220\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5224 - val_loss: 0.5249\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5183 - val_loss: 0.5260\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5232 - val_loss: 0.5258\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5217 - val_loss: 0.5222\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5521\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 2.3626 - val_loss: 1.2574\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2215 - val_loss: 0.9266\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8353 - val_loss: 0.7824\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7522 - val_loss: 0.7317\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7103 - val_loss: 0.6992\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6797 - val_loss: 0.6740\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6544 - val_loss: 0.6507\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6320 - val_loss: 0.6308\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6119 - val_loss: 0.6118\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5939 - val_loss: 0.5949\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5766 - val_loss: 0.5776\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5620 - val_loss: 0.5632\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5479 - val_loss: 0.5509\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5355 - val_loss: 0.5382\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5234 - val_loss: 0.5284\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5133 - val_loss: 0.5169\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5034 - val_loss: 0.5066\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4951 - val_loss: 0.4989\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4869 - val_loss: 0.4928\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4803 - val_loss: 0.4838\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4737 - val_loss: 0.4773\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4675 - val_loss: 0.4725\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4621 - val_loss: 0.4661\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4569 - val_loss: 0.4660\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4525 - val_loss: 0.4570\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4488 - val_loss: 0.4529\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4446 - val_loss: 0.4488\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4410 - val_loss: 0.4471\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4379 - val_loss: 0.4428\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4352 - val_loss: 0.4396\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4322 - val_loss: 0.4377\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4295 - val_loss: 0.4347\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4268 - val_loss: 0.4339\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4242 - val_loss: 0.4293\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4220 - val_loss: 0.4291\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4200 - val_loss: 0.4261\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4183 - val_loss: 0.4245\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4162 - val_loss: 0.4210\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4146 - val_loss: 0.4199\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4127 - val_loss: 0.4178\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4110 - val_loss: 0.4168\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4091 - val_loss: 0.4140\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4077 - val_loss: 0.4123\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4059 - val_loss: 0.4105\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4043 - val_loss: 0.4096\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4020 - val_loss: 0.4094\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4016 - val_loss: 0.4069\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4000 - val_loss: 0.4051\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3989 - val_loss: 0.4041\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3974 - val_loss: 0.4025\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3960 - val_loss: 0.4017\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3945 - val_loss: 0.4016\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3931 - val_loss: 0.4003\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3923 - val_loss: 0.3987\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3915 - val_loss: 0.3963\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3900 - val_loss: 0.3954\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3892 - val_loss: 0.3947\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3879 - val_loss: 0.3931\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3866 - val_loss: 0.3939\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3858 - val_loss: 0.3911\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3846 - val_loss: 0.3912\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3836 - val_loss: 0.3891\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3825 - val_loss: 0.3882\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3815 - val_loss: 0.3873\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3808 - val_loss: 0.3863\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3796 - val_loss: 0.3861\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3788 - val_loss: 0.3849\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3779 - val_loss: 0.3843\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3766 - val_loss: 0.3870\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3763 - val_loss: 0.3829\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3759 - val_loss: 0.3838\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3752 - val_loss: 0.3818\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3749 - val_loss: 0.3796\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3740 - val_loss: 0.3797\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3728 - val_loss: 0.3791\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3730 - val_loss: 0.3795\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3736 - val_loss: 0.3791\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3734 - val_loss: 0.3785\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3724 - val_loss: 0.3763\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3754 - val_loss: 0.3768\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3773 - val_loss: 0.3739\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3779 - val_loss: 0.3741\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3764 - val_loss: 0.3741\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3828 - val_loss: 0.3763\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3819 - val_loss: 0.3733\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3848 - val_loss: 0.3802\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3868 - val_loss: 0.3738\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3920 - val_loss: 0.3726\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3850 - val_loss: 0.3716\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3830 - val_loss: 0.3704\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3747 - val_loss: 0.3682\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3673 - val_loss: 0.3687\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3630 - val_loss: 0.3669\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3602 - val_loss: 0.3697\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3588 - val_loss: 0.3658\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3582 - val_loss: 0.3669\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.3643\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3565 - val_loss: 0.3641\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3555 - val_loss: 0.3639\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3549 - val_loss: 0.3630\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3537\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 2.5379 - val_loss: 1.1092\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8916 - val_loss: 0.8212\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7445 - val_loss: 0.7422\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6997 - val_loss: 0.7069\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6723 - val_loss: 0.6808\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6502 - val_loss: 0.6583\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6301 - val_loss: 0.6394\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6128 - val_loss: 0.6224\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5961 - val_loss: 0.6072\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5817 - val_loss: 0.5932\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5678 - val_loss: 0.5799\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5560 - val_loss: 0.5682\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5447 - val_loss: 0.5573\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5344 - val_loss: 0.5476\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5249 - val_loss: 0.5381\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5162 - val_loss: 0.5297\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5087 - val_loss: 0.5222\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5017 - val_loss: 0.5158\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4953 - val_loss: 0.5094\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4892 - val_loss: 0.5030\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4841 - val_loss: 0.4996\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4791 - val_loss: 0.4935\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4751 - val_loss: 0.4886\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4710 - val_loss: 0.4845\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4670 - val_loss: 0.4810\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4630 - val_loss: 0.4770\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4596 - val_loss: 0.4756\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4566 - val_loss: 0.4704\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4532 - val_loss: 0.4686\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4501 - val_loss: 0.4663\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4476 - val_loss: 0.4614\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4450 - val_loss: 0.4590\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4425 - val_loss: 0.4566\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4401 - val_loss: 0.4538\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4378 - val_loss: 0.4523\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4359 - val_loss: 0.4501\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4335 - val_loss: 0.4476\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4318 - val_loss: 0.4463\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4297 - val_loss: 0.4456\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4277 - val_loss: 0.4417\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4261 - val_loss: 0.4407\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4246 - val_loss: 0.4385\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4228 - val_loss: 0.4377\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4210 - val_loss: 0.4353\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4198 - val_loss: 0.4350\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4182 - val_loss: 0.4331\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4170 - val_loss: 0.4311\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4153 - val_loss: 0.4309\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4138 - val_loss: 0.4287\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4124 - val_loss: 0.4272\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4115 - val_loss: 0.4264\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4098 - val_loss: 0.4256\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4081 - val_loss: 0.4243\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4074 - val_loss: 0.4237\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4059 - val_loss: 0.4223\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4048 - val_loss: 0.4206\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4038 - val_loss: 0.4189\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4024 - val_loss: 0.4205\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4013 - val_loss: 0.4173\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4001 - val_loss: 0.4166\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3989 - val_loss: 0.4147\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3977 - val_loss: 0.4137\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3967 - val_loss: 0.4129\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3952 - val_loss: 0.4112\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3944 - val_loss: 0.4124\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3930 - val_loss: 0.4116\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3920 - val_loss: 0.4093\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3909 - val_loss: 0.4085\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3897 - val_loss: 0.4102\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3890 - val_loss: 0.4068\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3875 - val_loss: 0.4054\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3863 - val_loss: 0.4042\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3852 - val_loss: 0.4045\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3845 - val_loss: 0.4026\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3834 - val_loss: 0.4020\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3824 - val_loss: 0.4015\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3811 - val_loss: 0.3996\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3806 - val_loss: 0.3988\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3789 - val_loss: 0.3985\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3783 - val_loss: 0.3970\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3774 - val_loss: 0.3965\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3761 - val_loss: 0.3960\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3751 - val_loss: 0.3948\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3742 - val_loss: 0.3937\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3726 - val_loss: 0.3941\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3721 - val_loss: 0.3930\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3708 - val_loss: 0.3931\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3700 - val_loss: 0.3910\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3690 - val_loss: 0.3900\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3678 - val_loss: 0.3886\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3669 - val_loss: 0.3897\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3659 - val_loss: 0.3862\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3648 - val_loss: 0.3858\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3639 - val_loss: 0.3869\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3627 - val_loss: 0.3845\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3622 - val_loss: 0.3827\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3610 - val_loss: 0.3823\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3603 - val_loss: 0.3827\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3594 - val_loss: 0.3822\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3582 - val_loss: 0.3818\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3804\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.8224 - val_loss: 1.0055\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8343 - val_loss: 0.8044\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7369 - val_loss: 0.7406\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6873 - val_loss: 0.6970\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6493 - val_loss: 0.6596\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6177 - val_loss: 0.6301\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5910 - val_loss: 0.6040\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5677 - val_loss: 0.5811\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5481 - val_loss: 0.5616\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5313 - val_loss: 0.5445\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5171 - val_loss: 0.5303\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5047 - val_loss: 0.5184\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4945 - val_loss: 0.5071\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4848 - val_loss: 0.4982\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4767 - val_loss: 0.4886\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4692 - val_loss: 0.4811\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4621 - val_loss: 0.4744\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4561 - val_loss: 0.4674\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4499 - val_loss: 0.4630\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4446 - val_loss: 0.4575\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4397 - val_loss: 0.4511\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4351 - val_loss: 0.4471\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4310 - val_loss: 0.4445\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4275 - val_loss: 0.4398\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4238 - val_loss: 0.4376\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4209 - val_loss: 0.4351\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4183 - val_loss: 0.4311\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4151 - val_loss: 0.4273\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4133 - val_loss: 0.4263\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4110 - val_loss: 0.4236\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4085 - val_loss: 0.4223\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.4241\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4050 - val_loss: 0.4189\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4024 - val_loss: 0.4161\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4005 - val_loss: 0.4149\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3991 - val_loss: 0.4144\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3978 - val_loss: 0.4124\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3962 - val_loss: 0.4106\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3945 - val_loss: 0.4088\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3931 - val_loss: 0.4099\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3916 - val_loss: 0.4086\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3907 - val_loss: 0.4040\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3889 - val_loss: 0.4071\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3881 - val_loss: 0.4033\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3869 - val_loss: 0.4020\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3854 - val_loss: 0.4010\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3845 - val_loss: 0.4001\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3835 - val_loss: 0.3980\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3821 - val_loss: 0.4002\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.380 - 1s 3ms/step - loss: 0.3810 - val_loss: 0.3975\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3803 - val_loss: 0.3953\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3791 - val_loss: 0.3959\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3785 - val_loss: 0.3929\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3767 - val_loss: 0.3950\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3767 - val_loss: 0.3935\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3753 - val_loss: 0.3914\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3747 - val_loss: 0.3910\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3737 - val_loss: 0.3883\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3728 - val_loss: 0.3896\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3724 - val_loss: 0.3894\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3710 - val_loss: 0.3897\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3701 - val_loss: 0.3867\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3695 - val_loss: 0.3879\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3684 - val_loss: 0.3874\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3681 - val_loss: 0.3842\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3673 - val_loss: 0.3838\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3664 - val_loss: 0.3856\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3658 - val_loss: 0.3838\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3649 - val_loss: 0.3841\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3639 - val_loss: 0.3817\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3635 - val_loss: 0.3814\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3624 - val_loss: 0.3856\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3624 - val_loss: 0.3803\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3610 - val_loss: 0.3810\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3604 - val_loss: 0.3810\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3598 - val_loss: 0.3798\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3592 - val_loss: 0.3790\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3586 - val_loss: 0.3788\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3575 - val_loss: 0.3784\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3573 - val_loss: 0.3796\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3565 - val_loss: 0.3761\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3554 - val_loss: 0.3782\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3551 - val_loss: 0.3802\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3549 - val_loss: 0.3756\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3540 - val_loss: 0.3746\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3533 - val_loss: 0.3751\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3523 - val_loss: 0.3750\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3519 - val_loss: 0.3729\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3511 - val_loss: 0.3729\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3507 - val_loss: 0.3741\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3502 - val_loss: 0.3724\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3494 - val_loss: 0.3712\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3488 - val_loss: 0.3733\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3482 - val_loss: 0.3725\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3476 - val_loss: 0.3732\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3474 - val_loss: 0.3714\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3465 - val_loss: 0.3720\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3462 - val_loss: 0.3691\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3452 - val_loss: 0.3685\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3452 - val_loss: 0.3699\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3633\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7499 - val_loss: 0.5817\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6164 - val_loss: 0.4869\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5055 - val_loss: 0.4801\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8304 - val_loss: 0.5716\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1958 - val_loss: 0.7930\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7267 - val_loss: 0.7807\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5401 - val_loss: 0.4816\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4697 - val_loss: 0.4599\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4410 - val_loss: 0.4522\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4260 - val_loss: 0.4294\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4376 - val_loss: 0.4488\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4839 - val_loss: 0.4478\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4101 - val_loss: 0.4168\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3981 - val_loss: 0.4310\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4223 - val_loss: 0.4148\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4439 - val_loss: 0.4439\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4160 - val_loss: 0.4175\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3940 - val_loss: 0.4132\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4015 - val_loss: 0.3999\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3872 - val_loss: 0.4005\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3759 - val_loss: 0.3972\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3730 - val_loss: 0.4108\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3827 - val_loss: 0.4046\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3741 - val_loss: 0.3889\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3665 - val_loss: 0.3801\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3612 - val_loss: 0.3803\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3570 - val_loss: 0.3783\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3566 - val_loss: 0.3744\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3543 - val_loss: 0.3788\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3524 - val_loss: 0.3865\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3503 - val_loss: 0.3709\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3470 - val_loss: 0.3654\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3473 - val_loss: 0.3722\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3420 - val_loss: 0.3586\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3630 - val_loss: 0.3725\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3412 - val_loss: 0.3798\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3381 - val_loss: 0.3571\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3412 - val_loss: 0.3845\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3400 - val_loss: 0.3654\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3336 - val_loss: 0.3558\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3322 - val_loss: 0.3431\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3311 - val_loss: 0.3508\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3308 - val_loss: 0.3625\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3469 - val_loss: 0.3617\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3338 - val_loss: 0.3453\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3338 - val_loss: 0.3397\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3824 - val_loss: 0.3876\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3418 - val_loss: 0.3491\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3611 - val_loss: 0.3563\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3385 - val_loss: 0.3539\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3337 - val_loss: 0.3506\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3291 - val_loss: 0.3451\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3252 - val_loss: 0.3445\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3252 - val_loss: 0.3507\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3262 - val_loss: 0.3449\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3211 - val_loss: 0.3635\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3760\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8777 - val_loss: 1.0726\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: nan - val_loss: nan\n",
      "121/121 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 2.7578 - val_loss: 0.6497\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.6459 - val_loss: 0.6435\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.9455 - val_loss: 0.5826\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.2148 - val_loss: 0.7654\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 14.9564 - val_loss: 0.6956\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 37.0149 - val_loss: 1.4225\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 68.1149 - val_loss: 2.6648\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 218.4331 - val_loss: 5.2177\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 412.0957 - val_loss: 13.3712\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1012.4944 - val_loss: 33.7290\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3223.6418 - val_loss: 60.3830\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 6049.2056 - val_loss: 385.7359\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 19933.6406 - val_loss: 389.9428\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 15087.5371\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 2.1423 - val_loss: 0.8417\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7606 - val_loss: 0.7007\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6808 - val_loss: 0.6569\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6419 - val_loss: 0.6329\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6184 - val_loss: 0.6072\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6100 - val_loss: 0.5870\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5698 - val_loss: 0.5733\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5773 - val_loss: 0.5614\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5726 - val_loss: 0.5527\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5532 - val_loss: 0.5574\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5570 - val_loss: 0.5547\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5584 - val_loss: 0.5452\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5630 - val_loss: 0.5353\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5486 - val_loss: 0.5359\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5356 - val_loss: 0.5634\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5724 - val_loss: 0.5334\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5324 - val_loss: 0.5335\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5325 - val_loss: 0.5324\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5425 - val_loss: 0.5346\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5394 - val_loss: 0.5277\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5411 - val_loss: 0.5284\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5456 - val_loss: 0.5276\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5389 - val_loss: 0.5314\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5481 - val_loss: 0.5284\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5407 - val_loss: 0.5384\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5550 - val_loss: 0.5310\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5486 - val_loss: 0.5303\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5341 - val_loss: 0.5487\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5451 - val_loss: 0.5537\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5494 - val_loss: 0.5553\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5490 - val_loss: 0.5310\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5357 - val_loss: 0.5393\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5379\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 2.2771 - val_loss: 0.7018\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6896 - val_loss: 0.6251\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6343 - val_loss: 0.5804\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6433 - val_loss: 0.5822\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7168 - val_loss: 0.5591\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5878 - val_loss: 0.5635\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5714 - val_loss: 0.5383\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6653 - val_loss: 0.5538\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5692 - val_loss: 0.5324\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5656 - val_loss: 0.5427\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5522 - val_loss: 0.5343\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6329 - val_loss: 0.5373\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5549 - val_loss: 0.5270\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5555 - val_loss: 0.5327\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5998 - val_loss: 0.5269\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5873 - val_loss: 0.5308\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5788 - val_loss: 0.5244\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5344 - val_loss: 0.5296\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5315 - val_loss: 0.5211\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5357 - val_loss: 0.5310\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5277 - val_loss: 0.5230\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5679 - val_loss: 0.5323\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5641 - val_loss: 0.5208\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5569 - val_loss: 0.5303\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5310 - val_loss: 0.5207\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5367 - val_loss: 0.5295\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5319 - val_loss: 0.5206\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5339 - val_loss: 0.5274\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5446 - val_loss: 0.5255\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5256 - val_loss: 0.5297\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5272 - val_loss: 0.5255\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5230 - val_loss: 0.5270\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5182 - val_loss: 0.5247\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.519 - 0s 2ms/step - loss: 0.5212 - val_loss: 0.5241\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5199 - val_loss: 0.5229\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5216 - val_loss: 0.5266\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5244 - val_loss: 0.5230\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5510\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.5027 - val_loss: 0.7123\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 15.7484 - val_loss: 1.8985\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 84.7984 - val_loss: 40.7658\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1665.4742 - val_loss: 352.5393\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 86013.4688 - val_loss: 7462.0537\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1506240.1250 - val_loss: 108549.4141\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 7955238.5000 - val_loss: 3275034.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 145768672.0000 - val_loss: 35622928.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 8168317440.0000 - val_loss: 614570304.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 143901163520.0000 - val_loss: 10329229312.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 846171799552.0000 - val_loss: 178440749056.0000\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 7132963930112.0000\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 3.3658 - val_loss: 0.6406\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6027 - val_loss: 0.5806\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5917 - val_loss: 0.5533\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5646 - val_loss: 0.5400\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5643 - val_loss: 0.6018\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5492 - val_loss: 0.5309\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5953 - val_loss: 0.5446\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5748 - val_loss: 0.5527\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6456 - val_loss: 0.5297\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5430 - val_loss: 0.5738\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5680 - val_loss: 0.6691\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7122 - val_loss: 0.5338\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5293 - val_loss: 0.5274\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5373 - val_loss: 0.5301\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5371 - val_loss: 0.6215\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5973 - val_loss: 0.5428\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5386 - val_loss: 0.5282\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5355 - val_loss: 0.5304\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5473 - val_loss: 0.5352\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5395 - val_loss: 0.5278\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5839 - val_loss: 0.5313\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5417 - val_loss: 0.5303\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5577 - val_loss: 0.5264\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5922 - val_loss: 0.5267\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5613 - val_loss: 0.5271\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5625 - val_loss: 0.5259\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5489 - val_loss: 0.5601\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5381 - val_loss: 0.5288\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5929 - val_loss: 0.5307\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5449 - val_loss: 0.5333\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6175 - val_loss: 0.5349\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5430 - val_loss: 0.5577\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5877 - val_loss: 0.5563\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6541 - val_loss: 0.5301\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5356 - val_loss: 0.5378\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6416 - val_loss: 0.5486\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5523\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0775 - val_loss: 0.5792\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5959 - val_loss: 0.5480\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5980 - val_loss: 0.5355\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5446 - val_loss: 0.5314\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5316 - val_loss: 0.5493\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7250 - val_loss: 0.5291\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5230 - val_loss: 0.5333\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5300 - val_loss: 0.5281\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5241 - val_loss: 0.5392\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6127 - val_loss: 0.5515\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5407 - val_loss: 0.5271\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5240 - val_loss: 0.5413\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5344 - val_loss: 0.5249\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5207 - val_loss: 0.5277\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5342 - val_loss: 0.5213\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5477 - val_loss: 0.5196\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5675 - val_loss: 0.5198\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5304 - val_loss: 0.5219\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6510 - val_loss: 0.5250\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5296 - val_loss: 0.5445\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5323 - val_loss: 0.5237\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8407 - val_loss: 0.5344\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5303 - val_loss: 0.5309\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5470 - val_loss: 0.5258\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5169 - val_loss: 0.5203\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5441 - val_loss: 0.5168\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5487 - val_loss: 0.5250\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5881 - val_loss: 0.5262\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5297 - val_loss: 0.5384\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5334 - val_loss: 0.5182\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5355 - val_loss: 0.5188\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4716 - val_loss: 0.5371\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5338 - val_loss: 0.6276\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4639 - val_loss: 0.5461\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5323 - val_loss: 0.5199\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0650 - val_loss: 0.5667\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [-4.29120849e-01 -5.61991870e-01 -3.52717757e-01 -3.62610569e-01\n",
      " -4.49542969e-01 -3.42223259e+02 -3.65807593e-01             nan\n",
      " -5.02954201e+03 -2.37765464e+12]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9479 - val_loss: 0.6415\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5754 - val_loss: 0.5394\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5212 - val_loss: 0.4996\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5045 - val_loss: 0.4797\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5020 - val_loss: 0.4756\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4573 - val_loss: 0.4593\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4711 - val_loss: 0.4557\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4446 - val_loss: 0.4481\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4453 - val_loss: 0.4489\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4294 - val_loss: 0.4367\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4261 - val_loss: 0.4299\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4260 - val_loss: 0.4269\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4156 - val_loss: 0.4274\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4293 - val_loss: 0.4219\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4254 - val_loss: 0.4228\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4058 - val_loss: 0.4148\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4129 - val_loss: 0.4117\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4004 - val_loss: 0.4072\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4056 - val_loss: 0.4108\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3924 - val_loss: 0.4025\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3936 - val_loss: 0.3992\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3911 - val_loss: 0.3991\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3886 - val_loss: 0.3923\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3846 - val_loss: 0.3919\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4431 - val_loss: 0.3918\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4364 - val_loss: 0.3908\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3952 - val_loss: 0.3962\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3918 - val_loss: 0.3904\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3784 - val_loss: 0.3871\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3815 - val_loss: 0.3876\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3846 - val_loss: 0.3931\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3780 - val_loss: 0.3824\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3774 - val_loss: 0.3864\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4149 - val_loss: 0.3954\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3782 - val_loss: 0.3862\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3712 - val_loss: 0.3794\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3761 - val_loss: 0.3806\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3697 - val_loss: 0.3756\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3699 - val_loss: 0.3767\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3633 - val_loss: 0.3705\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3694 - val_loss: 0.3782\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3632 - val_loss: 0.3738\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3640 - val_loss: 0.3694\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3597 - val_loss: 0.3728\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3559 - val_loss: 0.3676\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3570 - val_loss: 0.3700\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3557 - val_loss: 0.3814\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3627 - val_loss: 0.3638\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3520 - val_loss: 0.3622\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3503 - val_loss: 0.3621\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3509 - val_loss: 0.3685\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3557 - val_loss: 0.3655\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3495 - val_loss: 0.3573\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3452 - val_loss: 0.3605\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3455 - val_loss: 0.3618\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3600 - val_loss: 0.3566\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3477 - val_loss: 0.3543\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3491 - val_loss: 0.3584\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3676 - val_loss: 0.3599\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3931 - val_loss: 0.3587\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3476 - val_loss: 0.3627\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3450 - val_loss: 0.3539\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3570 - val_loss: 0.3649\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3612 - val_loss: 0.3617\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3471 - val_loss: 0.3555\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3382 - val_loss: 0.3548\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3890 - val_loss: 0.3550\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3454 - val_loss: 1.1155\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4111 - val_loss: 0.3594\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3454 - val_loss: 0.3508\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3405 - val_loss: 0.3559\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3460 - val_loss: 0.3491\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3430 - val_loss: 0.3535\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3419 - val_loss: 0.3509\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3366 - val_loss: 0.3616\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3442 - val_loss: 0.3616\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3351 - val_loss: 0.3494\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3334 - val_loss: 0.3486\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3330 - val_loss: 0.4204\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3491 - val_loss: 0.3460\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3306 - val_loss: 0.3422\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3316 - val_loss: 0.3423\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3330 - val_loss: 0.3499\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3291 - val_loss: 0.3403\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3270 - val_loss: 0.3381\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3286 - val_loss: 0.3394\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3331 - val_loss: 0.3716\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3380 - val_loss: 0.3386\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3289 - val_loss: 0.3394\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3327 - val_loss: 0.3415\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3251 - val_loss: 0.3397\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3304 - val_loss: 0.3350\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3275 - val_loss: 0.3354\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3233 - val_loss: 0.3346\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3216 - val_loss: 0.3426\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3302 - val_loss: 0.3374\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3221 - val_loss: 0.3369\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3206 - val_loss: 0.3372\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3427 - val_loss: 0.4004\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3546 - val_loss: 0.3357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x0000027A11177670>,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000027A1364F5E0>,\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_distribs = {\n",
    " \"n_hidden\": [0, 1, 2, 3],\n",
    " \"n_neurons\": np.arange(1, 100),\n",
    " \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(x_train, y_train, epochs=100,\n",
    " validation_data=(x_valid, y_valid),\n",
    " callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1f8f6f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.005349945136965967, 'n_hidden': 1, 'n_neurons': 66}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9ba236a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3527177572250366"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e0c681bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8ced5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
